{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harvard NLP 의 [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)를 구현하는 것을 목표로 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(context='talk')\n",
    "%matplotlib inline\n",
    "\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구조\n",
    "\n",
    "<img src='./transformer.png'>\n",
    "\n",
    "인코더와 디코더로 분리되어 있으며, 각각은 동일한 구조의 레이어를 여러번 반복 적용하는 형태로 이루어져 있다. 이 모델에서는 동일한 레이어를 반복하여 쌓는 일이 많으므로 다음 함수를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"N개의 동일한 레이어를 생성한다.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sublayer 정의\n",
    "\n",
    "향후 인코더/디코더 정의에 필요한 layer normalization과 sublayer connection, feed-forward net, 그리고 self-attention을 구현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Layer Normalization\n",
    "\n",
    "뉴런 $x = (x_1, \\ldots, x_m)$ 의 Layer normalization 은 다음과 같이 정의된다.\n",
    "\n",
    "$$ \\bar{x} =  \\frac{a}{\\sigma} ( x - \\mu) + b.$$\n",
    "\n",
    "여기서 $\\mu = \\frac1m \\sum x_i, \\sigma = \\sqrt{\\frac1m \\sum(x_i - \\mu)}$이며, $a, b$는 학습되는 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Layer normalization 계층을 구성한다.\"\n",
    "    def __init__(self, size, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(size))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(size))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x-mean) / (std+self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sublayer Connection\n",
    "\n",
    "임의의 sublayer에 residual connection과 layer normalization, dropout을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    임의의 sublayer에 대해 residual connection과 layer normalization을 적용한다.\n",
    "    이때 드랍아웃 또한 적용하여 오버피팅을 방지한다.\n",
    "    구현의 편의를 위해 normalization은 입력에서 적용한다.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        # 입력으로 x 뿐 아니라 sublayer를 받아야함!\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feed-forward net\n",
    "\n",
    "토큰 단위로 FFN을 적용하는 Positionwise FFN 을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    FFN 구현. d_model 차원의 입력값을 d_ff 차원의 공간에 임베딩한 후 \n",
    "    relu 함수를 취한 후 다시 d_model 차원으로 임베딩한다.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multi-head Attention\n",
    "\n",
    "먼저, 쿼리(Q), 키(K), 값(V)를 입력으로 받아서 아래 그림처럼 연산을 처리하는 atttention 함수를 구현한다. 이때 scale 과정은 $\\sqrt{d_k}$로 나눠주는 것이다.\n",
    "\n",
    "<img src=./attention.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Scaled Dot Product Attention을 구현한다.\"\n",
    "    d_k = query.size(-1) # query size = (length, d_k)\n",
    "    scores = torch.matmul(query, key.transpose(-2,-1)) / math.sqrt(d_k)\n",
    "    # scores size = (length, length)\n",
    "    if mask is not None:\n",
    "        # 마스크가 False(=0)인 점은 -10^9 로 채워 학습되는 것을 방지\n",
    "        scores = scores.masked_fill(mask ==0 , -1e9) \n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    # p_attn size = (length)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "    # return size = (length, d_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 정의된 attention 함수를 여러개 쌓아올린 multi-head attention 을 구현한다.\n",
    "\n",
    "<img src=./multi-head_attention.png width=250>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"h : head 갯수, d_model : 모델 차원.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0 # 입력 벡터를 h개로 나눠야하므로 체크 필요\n",
    "        self.d_k = d_model // h # 정수로 처리하기 위해 // 사용\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        # 위 그림에 linear module이 4개 필요\n",
    "        self.attn = None \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # 마스크를 모든 head에 동일하게 적용한다.\n",
    "            mask = mask.unsqueeze(1) # 마스크 벡터의 head 부분에 해당하는 값을 1로 채움\n",
    "        nbatches = query.size(0) # query size : (nbatches, length, d_model)\n",
    "        \n",
    "        # 1) Q, K, V 에 linear projection을 취한 후 사이즈 변환 => h x d_k\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
    "            for l, x in zip(self.linears, (query, key, value))]\n",
    "        # size : (nbatches, h, length, d_k)\n",
    "        \n",
    "        # 2) (length, d_k) 사이즈의 벡터들에 attention을 h번 적용\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        # x size : (nbatches, h, length, d_k)\n",
    "        \n",
    "        # 3) x를 이어붙인 후 마지막 linear projection 적용\n",
    "        x = x.transpose(1,2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x) # size : (nbatches, length, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인코더\n",
    "\n",
    "<img src='./transformer.png'>\n",
    "\n",
    "인코더는 $N=6$개의 인코더 레이어를 쌓아서 만든다. 따라서 인코더 레이어(layer)와 $N$을 초기값으로 받으며, 입력값을 각 인코더 레이어에 반복 적용한 값을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"인코더는 N개의 레이어로 구성된다.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"입력값(과 마스크)를 각각의 레이어에 통과시킨다.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코더 레이어\n",
    "\n",
    "인코더에서 반복 적용되는 레이어를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"인코더 레이어는 셀프어텐션과 FFN으로 이루어져 있다.\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        sublayer는 입력값 x뿐 아니라 적용할 layer도 입력으로 받아야함.\n",
    "        sublayer[0]은 self_attn, sublayer[1]은 FFN을 적용 layer로 사용한다.\n",
    "        \"\"\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask)) \n",
    "        # 입력값도 패딩으로 인한 마스킹 필요\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디코더\n",
    "\n",
    "인코더와 동일하게 $N=6$개의 디코더 레이어를 쌓아서 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"N개의 디코더 레이어로 구성\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"memory는 인코더의 출력값으로, 디코더 레이어의 두번째 self_attn의 입력에 사용\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디코더 레이어\n",
    "\n",
    "인코더에 비해 디코더는 하나의 서브레이어가 더 필요하며, 여기서는 인코더의 아웃풋을 받아서 멀티헤드 셀프어텐션을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"셀프어텐션, 소스어텐션, FFN으로 구성한다.\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn # 입력값을 연산\n",
    "        self.src_attn = src_attn # 쿼리는 입력값, 키와 밸류는 인코더의 출력값을 입력\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"\"\"\n",
    "        sublayer[0]은 self_attn, sublayer[1]은 src_attn,\n",
    "        sublayer[2]는 FFN을 적용 layer로 사용한다. \n",
    "        \"\"\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x,x,x,tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x,m,m,src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마스킹\n",
    "\n",
    "디코더 레이어의 셀프어텐션이 현재의 입력값 이후의 값을 참조하지 못하도록 마스킹이 필요하다. 다시 말해, $i$번째 위치의 값을 예측하는데에는 $i$보다 앞에 나오는 단어들만 참조하도록 구성해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"마스킹 생성\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0 # 대각선 아래만 True, 위에는 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy.triu($m, k=0$)\n",
    "Upper triangle of an array. Return a copy of a matrix with the elements below the $k$-th diagonal zeroed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 1.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.triu(np.ones([4,4]), k=1))\n",
    "print(np.triu(np.ones([4,4]), k=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False, False],\n",
       "         [ True,  True, False, False, False],\n",
       "         [ True,  True,  True, False, False],\n",
       "         [ True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True,  True]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequent_mask(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(subsequent_mask(20)[0])\n",
    "plt.show()\n",
    "# 각각의 타겟 단어(행)가 참조할 수 있는 범위(열)을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임베딩\n",
    "\n",
    "### 1. 임베딩 레이어\n",
    "\n",
    "입력과 출력 언어의 단어를 공유하는 하나의 Embedding을 생성한다. 이때, weight에 $\\sqrt{d_{model}}$을 곱하여 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Positional Encoding\n",
    "\n",
    "$$\n",
    "\\text{PE}_{(pos,2i)} = \\sin(pos/10000^{2i/{d_{model}}}) \\\\\n",
    "\\text{PE}_{(pos,2i+1)} = \\cos(pos/10000^{2i/{d_{model}}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"입력값에 PE를 더하는 모듈 구성.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000, dev=dev):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.pe = torch.zeros([max_len, d_model],requires_grad=False).to(dev)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1) # (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                            - (math.log(10000.0) / d_model)) # (d_model/2)\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = (self.pe).unsqueeze(0) # (1, max_len, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)] # x의 length까지만 필요함\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "위에서 주어진 레이어들을 토대로 실제 모델을 정의하자. 먼저 인코더와 디코더로 구성되는 모델의 기본 구조 밑 단어 생성자를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    표준적인 인코더-디코더 모델 구현\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        \"입력값(단어 index)을 받아서 인코딩\"\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        \"결과값(index)과 인코더의 어텐션의 출력을 받아서 디코딩\"\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"인코더의 출력값을 메모리 입력값으로 받아서 순전파\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"일반적인 linear + softmax 계층 구현.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "        # 벡터를 단어로 변환\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 정의한 레이어들을 이용하여 드디어 모델 구현...\n",
    "\n",
    "<img src=./transformer.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=4,\n",
    "               d_model=256, d_ff=1024, h=4, dropout=0.1):\n",
    "    \"하이퍼파라미터들로부터 모델 생성\"\n",
    "    c = copy.deepcopy # 클래스 생성 후 deepcopy하여 사용\n",
    "    \n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    \n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout),N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab)\n",
    "    )\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model = make_model(10,10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련\n",
    "\n",
    "## 배치와 마스킹 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"트레이닝 배치를 받아서 마스킹과 디코더의 입력/출력 분해 구현.\"\n",
    "    def __init__(self, src, trg=None, pad=0, dev=dev):\n",
    "        self.src = src.to(dev)\n",
    "        self.src_mask = (src != pad).unsqueeze(-2).to(dev) # 패딩(0) 외에는 True\n",
    "        self.dev = dev\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1] # 마지막 단어는 디코더의 입력으로 넣지 않음\n",
    "            self.trg_y = trg[:, 1:] # 디코더의 결과값의 ground truth\n",
    "            self.trg_mask = self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum() \n",
    "            \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2).to(dev) # 패딩 외에는 True\n",
    "        tgt_mask = (tgt_mask & subsequent_mask(tgt.size(-1)).to(dev)).type_as(tgt_mask.data)\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "아담 옵티마이저를 $\\beta_1=0.9$, $\\beta_2=0.98$ and $\\epsilon=10^{-9}$ 옵션으로 구현한다. 그리고 warmup step을 4000으로 하여 warm start를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step=None):\n",
    "        \"Implement 'lrate'\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * (self.model_size ** (-0.5) * \n",
    "                             min(step**(-0.5), step * self.warmup**(-1.5)))\n",
    "    \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000, \n",
    "                  torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Three settings of the lrate hyperparameters.\n",
    "opts = [NoamOpt(512, 1, 4000, None), \n",
    "        NoamOpt(512, 1, 8000, None),\n",
    "        NoamOpt(256, 1, 4000, None)]\n",
    "plt.plot(np.arange(1, 20000), [[opt.rate(i) for opt in opts] for i in range(1, 20000)])\n",
    "plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data loading.\n",
    "from torchtext import data, datasets\n",
    "\n",
    "import spacy\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "BLANK_WORD = \"<blank>\"\n",
    "SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD)\n",
    "TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, \n",
    "                 eos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
    "\n",
    "MAX_LEN = 100\n",
    "train, val, test = datasets.IWSLT.splits(\n",
    "    exts=('.de', '.en'), fields=(SRC, TGT), \n",
    "    filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "        len(vars(x)['trg']) <= MAX_LEN)\n",
    "MIN_FREQ = 2\n",
    "SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "TGT.build_vocab(train.trg, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58790, 36323)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SRC.vocab), len(TGT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator\n",
    "\n",
    "train_loader = Iterator(train, \n",
    "                        batch_size=32, \n",
    "                        device=dev,#torch.device('cpu'),  \n",
    "                        repeat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, optim, optim_rate, loss_compute, epoch_num):\n",
    "    \"일반적인 훈련 모델 구현\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, data in enumerate(data_iter):\n",
    "        batch = Batch(data.src.transpose(0,1), data.trg.transpose(0,1))\n",
    "        #out = model(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "        out = model(batch.src.to(dev), batch.trg.to(dev), batch.src_mask.to(dev), batch.trg_mask.to(dev))\n",
    "        res = model.generator(out)\n",
    "#         print('out size : {}, res size : {}, batch.trg_y size : {}'.\n",
    "#               format(out.size(), res.size(), batch.trg_y.size()))\n",
    "        optim.zero_grad()\n",
    "        loss = loss_compute(res.contiguous().view(-1,res.size(-1)), batch.trg_y.contiguous().view(-1))\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        loss.backward()\n",
    "        optim_rate.step()\n",
    "        if i % 1000 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch: %d Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                 (epoch_num, i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성 후 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(58790, 256)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(36323, 256)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=256, out_features=36323, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(len(SRC.vocab), len(TGT.vocab), N=4,\n",
    "               d_model=256, d_ff=1024, h=4, dropout=0.1)\n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
    "opt_rate = NoamOpt(model.src_embed[0].d_model, 2, 4000, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 330.00 MiB (GPU 0; 5.81 GiB total capacity; 4.63 GiB already allocated; 76.50 MiB free; 68.67 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8238d704d925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-979fdeae1293>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_iter, model, optim, optim_rate, loss_compute, epoch_num)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#out = model(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print('out size : {}, res size : {}, batch.trg_y size : {}'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#               format(out.size(), res.size(), batch.trg_y.size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/Pytorch_ev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-9f72e50d7d29>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Python/Pytorch_ev/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 330.00 MiB (GPU 0; 5.81 GiB total capacity; 4.63 GiB already allocated; 76.50 MiB free; 68.67 MiB cached)"
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "for i in range(epoch):\n",
    "    run_epoch(train_loader, model, opt, opt_rate, loss_f, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'Transformer_epoch_{}.pt'.format(epoch)\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Transformer_epoch_3.pt'\n",
    "model2 = make_model(len(SRC.vocab), len(TGT.vocab), N=4,\n",
    "               d_model=256, d_ff=1024, h=4, dropout=0.1)\n",
    "model2.to(dev)\n",
    "model2.load_state_dict(torch.load(path))\n",
    "model2.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
