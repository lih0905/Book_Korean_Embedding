{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 NPLM (Neural Probability Language Model)\n",
    "\n",
    "NPLM을 파이토치로 구현해보자!\n",
    "\n",
    "<img src = 'images/NPLM.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4 # n-gram의 갯수\n",
    "VEC_DIM = 100 # 임베딩 차원\n",
    "HIDDEN_DIM = 100 # 은닉 차원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 먼저 데이터를 벡터화부터 시작하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = 'data/tokenized/korquad_mecab.txt'\n",
    "corpus = [sent.strip().split() for sent in open(txt_path, 'r', encoding='utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바그너\n",
      "는\n",
      "괴테\n",
      "의\n",
      "파우스트\n",
      "를\n",
      "읽\n",
      "고\n",
      "무엇\n",
      "을\n",
      "쓰\n",
      "고자\n",
      "했\n",
      "는가\n",
      "?\n",
      "교향곡\n"
     ]
    }
   ],
   "source": [
    "for word in corpus[1]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_ngram(n, sent):\n",
    "    ngrams = []\n",
    "    \n",
    "    for i in range(len(sent)-n+1):\n",
    "        ngram = []\n",
    "        for j in range(n):\n",
    "            ngram.append(sent[i+j])\n",
    "        ngrams.append(ngram)\n",
    "            \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['바그너', '는', '괴테', '의'],\n",
       " ['는', '괴테', '의', '파우스트'],\n",
       " ['괴테', '의', '파우스트', '를'],\n",
       " ['의', '파우스트', '를', '읽'],\n",
       " ['파우스트', '를', '읽', '고'],\n",
       " ['를', '읽', '고', '무엇'],\n",
       " ['읽', '고', '무엇', '을'],\n",
       " ['고', '무엇', '을', '쓰'],\n",
       " ['무엇', '을', '쓰', '고자'],\n",
       " ['을', '쓰', '고자', '했'],\n",
       " ['쓰', '고자', '했', '는가'],\n",
       " ['고자', '했', '는가', '?'],\n",
       " ['했', '는가', '?', '교향곡']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_to_ngram(N, corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어장과 인덱스를 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for i in range(len(corpus)):\n",
    "    vocab.update(corpus[i])\n",
    "    \n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83593"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id = dict()\n",
    "for word in vocab:\n",
    "    word_to_id[word]=len(word_to_id)    \n",
    "\n",
    "len(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deluge': 0,\n",
       " '정충': 1,\n",
       " '長': 2,\n",
       " 'affinity': 3,\n",
       " '화질': 4,\n",
       " '총감독': 5,\n",
       " '辰': 6,\n",
       " '생겼': 7,\n",
       " '관조': 8,\n",
       " '恤': 9,\n",
       " '나폴레옹': 10,\n",
       " '고위직': 11,\n",
       " '엔네아드': 12,\n",
       " '이타야': 13,\n",
       " '포켓형': 14,\n",
       " '안치': 15,\n",
       " '방해죄': 16,\n",
       " '묻': 17,\n",
       " '쓰러뜨렸으나': 18,\n",
       " '반짝이': 19,\n",
       " '입장객': 20,\n",
       " '코핀': 21,\n",
       " '보슬리': 22,\n",
       " '매슈': 23,\n",
       " 'Treblinka': 24,\n",
       " '베스타': 25,\n",
       " '소카': 26,\n",
       " '두르가': 27,\n",
       " '김윤미': 28,\n",
       " '타르지': 29,\n",
       " '최인': 30,\n",
       " '콘코': 31,\n",
       " '히로시': 32,\n",
       " '한효주': 33,\n",
       " '하코트': 34,\n",
       " '불러온다': 35,\n",
       " '에마누엘레': 36,\n",
       " '수파': 37,\n",
       " '주원인': 38,\n",
       " '레이지': 39,\n",
       " '천대': 40,\n",
       " '그서': 41,\n",
       " '청담': 42,\n",
       " '불타오르': 43,\n",
       " '냄새샘': 44,\n",
       " '페널티킥': 45,\n",
       " '권문세족': 46,\n",
       " '영포': 47,\n",
       " '봄베이': 48,\n",
       " '영영': 49,\n",
       " '아리안나': 50,\n",
       " '서유견문': 51,\n",
       " '이이다': 52,\n",
       " '국자': 53,\n",
       " '축대': 54,\n",
       " '노란': 55,\n",
       " '>(': 56,\n",
       " '이시아': 57,\n",
       " '부사': 58,\n",
       " '愁城': 59,\n",
       " '균형발전': 60,\n",
       " '과전': 61,\n",
       " '수양버들': 62,\n",
       " '페럴': 63,\n",
       " '식힌다': 64,\n",
       " '번영': 65,\n",
       " '몇대': 66,\n",
       " '들어차': 67,\n",
       " '스머프': 68,\n",
       " '제멋': 69,\n",
       " 'ICLEI': 70,\n",
       " '시끄러운': 71,\n",
       " '기영': 72,\n",
       " '투생': 73,\n",
       " '맞아떨어지': 74,\n",
       " '리쿠': 75,\n",
       " '성배': 76,\n",
       " '조각자': 77,\n",
       " '칙스': 78,\n",
       " '칭할': 79,\n",
       " 'nH': 80,\n",
       " '헤스': 81,\n",
       " '가진다는': 82,\n",
       " '빙그레': 83,\n",
       " '都巡': 84,\n",
       " '종이돈': 85,\n",
       " '본회퍼': 86,\n",
       " '박철원': 87,\n",
       " '팽도리': 88,\n",
       " '체': 89,\n",
       " '屬官': 90,\n",
       " '남악': 91,\n",
       " '위압': 92,\n",
       " 'Colours': 93,\n",
       " 'Benson': 94,\n",
       " '및': 95,\n",
       " '누리꾼': 96,\n",
       " '잔존물': 97,\n",
       " '허슬': 98,\n",
       " '옯겨진다': 99,\n",
       " '테오': 100,\n",
       " '싸워야': 101,\n",
       " '지키': 102,\n",
       " '보행': 103,\n",
       " '바뀐지': 104,\n",
       " '레퍼토리': 105,\n",
       " 'central': 106,\n",
       " 'ˠ': 107,\n",
       " '통치권자': 108,\n",
       " '석의': 109,\n",
       " 'Massena': 110,\n",
       " '두꺼비': 111,\n",
       " '돈다는': 112,\n",
       " '중고': 113,\n",
       " '티알프': 114,\n",
       " '혈액형': 115,\n",
       " 'understanding': 116,\n",
       " '약점': 117,\n",
       " '閔': 118,\n",
       " '염경엽': 119,\n",
       " '와우': 120,\n",
       " '니나': 121,\n",
       " '청진시': 122,\n",
       " '컴뱃': 123,\n",
       " '導': 124,\n",
       " '물리학자': 125,\n",
       " '셰필드': 126,\n",
       " '정시운': 127,\n",
       " '구제역': 128,\n",
       " 'meets': 129,\n",
       " '아메네': 130,\n",
       " '적통': 131,\n",
       " '싸우': 132,\n",
       " '격지자': 133,\n",
       " '둥양': 134,\n",
       " '정실': 135,\n",
       " '까칠': 136,\n",
       " '해군': 137,\n",
       " '부딪치': 138,\n",
       " '시정책': 139,\n",
       " '잠적': 140,\n",
       " '풀려났': 141,\n",
       " '목소리': 142,\n",
       " '醍醐': 143,\n",
       " '천연자원': 144,\n",
       " '만질': 145,\n",
       " '영재교육': 146,\n",
       " '디파이': 147,\n",
       " '다선': 148,\n",
       " '_': 149,\n",
       " '이루어진다는': 150,\n",
       " '최주남': 151,\n",
       " 'Amt': 152,\n",
       " '윌턴': 153,\n",
       " '유라시안': 154,\n",
       " '히로마사': 155,\n",
       " '핑장': 156,\n",
       " '思想': 157,\n",
       " '누계': 158,\n",
       " '스미요시': 159,\n",
       " 'Meeting': 160,\n",
       " '안식교': 161,\n",
       " '해럴드': 162,\n",
       " '에비뉴': 163,\n",
       " '도처': 164,\n",
       " 'Cornelius': 165,\n",
       " '고토쿠': 166,\n",
       " '가마이': 167,\n",
       " 'frog': 168,\n",
       " '폰타나': 169,\n",
       " '류': 170,\n",
       " 'arte': 171,\n",
       " '시정': 172,\n",
       " 'Stangl': 173,\n",
       " '무궁화동산': 174,\n",
       " '심복': 175,\n",
       " '최제우': 176,\n",
       " '원류': 177,\n",
       " '건넨다': 178,\n",
       " '커튼': 179,\n",
       " 'Quiero': 180,\n",
       " '압하스': 181,\n",
       " '시시': 182,\n",
       " '멩겔레': 183,\n",
       " '급소': 184,\n",
       " '곽정숙': 185,\n",
       " '구속적부심사': 186,\n",
       " '예외': 187,\n",
       " '정사면체': 188,\n",
       " 'foreign': 189,\n",
       " '지급시': 190,\n",
       " '편달': 191,\n",
       " '불법체류': 192,\n",
       " '텡': 193,\n",
       " '이메이': 194,\n",
       " '박동혁': 195,\n",
       " 'Moribond': 196,\n",
       " '맺혔': 197,\n",
       " 'СССР': 198,\n",
       " '나오스케': 199,\n",
       " 'Sendra': 200,\n",
       " '파본': 201,\n",
       " '광둥어': 202,\n",
       " '심은진': 203,\n",
       " '종축': 204,\n",
       " '세마루': 205,\n",
       " '彌': 206,\n",
       " '제정신': 207,\n",
       " '주의력': 208,\n",
       " 'Recommendation': 209,\n",
       " 'WDR': 210,\n",
       " '뒤쳐졌': 211,\n",
       " '인방': 212,\n",
       " '소득세법': 213,\n",
       " '애원': 214,\n",
       " '홍승하': 215,\n",
       " '부독': 216,\n",
       " '아그레망': 217,\n",
       " '샌드위치': 218,\n",
       " '주북': 219,\n",
       " '웅진': 220,\n",
       " '明史': 221,\n",
       " '박현철': 222,\n",
       " '마비': 223,\n",
       " '의흥친군좌위': 224,\n",
       " '합병증': 225,\n",
       " '발고': 226,\n",
       " 'のままで': 227,\n",
       " '스카디': 228,\n",
       " '튜링상': 229,\n",
       " '감해': 230,\n",
       " '준박': 231,\n",
       " 'maculatus': 232,\n",
       " '이보형': 233,\n",
       " '동남리': 234,\n",
       " '사이키델릭': 235,\n",
       " 'aggregation': 236,\n",
       " '잔드': 237,\n",
       " '신이마미야': 238,\n",
       " '원음': 239,\n",
       " '다보스': 240,\n",
       " '顎': 241,\n",
       " '장폭': 242,\n",
       " '리친': 243,\n",
       " '기름져': 244,\n",
       " '뱀장어과': 245,\n",
       " '알락': 246,\n",
       " 'AAU': 247,\n",
       " '바스': 248,\n",
       " '촘촘': 249,\n",
       " '마그네슘': 250,\n",
       " '조희': 251,\n",
       " '貴妃': 252,\n",
       " '단전': 253,\n",
       " 'UDT': 254,\n",
       " '빌리스': 255,\n",
       " '《‘': 256,\n",
       " '어떤지를': 257,\n",
       " '약체화': 258,\n",
       " '복잡화': 259,\n",
       " 'integral': 260,\n",
       " '법화': 261,\n",
       " 'enterprise': 262,\n",
       " '반한': 263,\n",
       " 'CMA': 264,\n",
       " '벵게트': 265,\n",
       " 'Yīng': 266,\n",
       " '반역자': 267,\n",
       " '노예사냥': 268,\n",
       " '두미트레스쿠': 269,\n",
       " '수궁가': 270,\n",
       " '武': 271,\n",
       " '부티크': 272,\n",
       " '잡아오': 273,\n",
       " 'Δ': 274,\n",
       " '미네소타주': 275,\n",
       " '뗀': 276,\n",
       " 'Science': 277,\n",
       " '완전체': 278,\n",
       " '사공영진': 279,\n",
       " 'huszár': 280,\n",
       " '헌제': 281,\n",
       " '현석호': 282,\n",
       " 'Vambraces': 283,\n",
       " 'conjunctions': 284,\n",
       " '점근': 285,\n",
       " '마정길': 286,\n",
       " '의향': 287,\n",
       " '肅愼': 288,\n",
       " '정찰기': 289,\n",
       " '주체사상': 290,\n",
       " '先後': 291,\n",
       " 'Florida': 292,\n",
       " '템포': 293,\n",
       " '변한': 294,\n",
       " '금고형': 295,\n",
       " '몬무': 296,\n",
       " 'Lambert': 297,\n",
       " '퍼트넘': 298,\n",
       " '트래': 299,\n",
       " '섬유': 300,\n",
       " '사범': 301,\n",
       " '김태우': 302,\n",
       " 'ちゃん': 303,\n",
       " '최두일': 304,\n",
       " '낚시': 305,\n",
       " '뒤쳐질': 306,\n",
       " '악기': 307,\n",
       " '윤건': 308,\n",
       " '두른': 309,\n",
       " '백화제방': 310,\n",
       " '의민': 311,\n",
       " '불꽃': 312,\n",
       " '련정': 313,\n",
       " '신경전': 314,\n",
       " '이튿날': 315,\n",
       " '시극': 316,\n",
       " '대공습': 317,\n",
       " 'Ordinary': 318,\n",
       " '그렉': 319,\n",
       " '지선': 320,\n",
       " '노먼': 321,\n",
       " '동이면': 322,\n",
       " '아델라이드': 323,\n",
       " 'PSCs': 324,\n",
       " '습윤': 325,\n",
       " '집대성': 326,\n",
       " 'spike': 327,\n",
       " 'uncle': 328,\n",
       " '변절자': 329,\n",
       " '선왕': 330,\n",
       " '수장': 331,\n",
       " '급변': 332,\n",
       " '김성주': 333,\n",
       " '미끄러졌': 334,\n",
       " '문대': 335,\n",
       " '지지': 336,\n",
       " '하나무라': 337,\n",
       " 'Cattell': 338,\n",
       " '막골': 339,\n",
       " '원뿔형': 340,\n",
       " '열린다는': 341,\n",
       " '은은': 342,\n",
       " '이덕무': 343,\n",
       " '綰': 344,\n",
       " '다산': 345,\n",
       " '김용철': 346,\n",
       " '이선균': 347,\n",
       " '칭푸': 348,\n",
       " '광수': 349,\n",
       " '오케스트라': 350,\n",
       " '베르망': 351,\n",
       " '불쾌지수': 352,\n",
       " 'Airplay': 353,\n",
       " '戰': 354,\n",
       " '경일': 355,\n",
       " '책임졌': 356,\n",
       " '－': 357,\n",
       " '어택': 358,\n",
       " '킬': 359,\n",
       " '박종원': 360,\n",
       " 'GRIN': 361,\n",
       " '속새': 362,\n",
       " '신진대사': 363,\n",
       " '줄이': 364,\n",
       " '황비홍': 365,\n",
       " '반빌': 366,\n",
       " '행은': 367,\n",
       " '개작': 368,\n",
       " '모자랐': 369,\n",
       " 'Rauschgiftbekämpfung': 370,\n",
       " '망가져': 371,\n",
       " 'Bubblegum': 372,\n",
       " '상징': 373,\n",
       " '물거품': 374,\n",
       " '확신': 375,\n",
       " '정신주의': 376,\n",
       " '마렐라': 377,\n",
       " '수정': 378,\n",
       " 'Morphogenesis': 379,\n",
       " '끌어당기': 380,\n",
       " '파투': 381,\n",
       " 'ward': 382,\n",
       " '도키': 383,\n",
       " '중령': 384,\n",
       " '제기동': 385,\n",
       " '포석': 386,\n",
       " 'Piquette': 387,\n",
       " '복면': 388,\n",
       " '지명': 389,\n",
       " '각급': 390,\n",
       " '두로': 391,\n",
       " 'Blegen': 392,\n",
       " '전성환': 393,\n",
       " '깃털': 394,\n",
       " '상묘': 395,\n",
       " '사회주의': 396,\n",
       " 'KARA': 397,\n",
       " '커터칼': 398,\n",
       " 'Carlill': 399,\n",
       " '서포': 400,\n",
       " '조선우': 401,\n",
       " '나르': 402,\n",
       " '부레쓰': 403,\n",
       " '진국': 404,\n",
       " '드베어': 405,\n",
       " '받아들일': 406,\n",
       " '聖節': 407,\n",
       " '분규': 408,\n",
       " '장가': 409,\n",
       " 'فيلم': 410,\n",
       " '레슬러': 411,\n",
       " 'Virginia': 412,\n",
       " '家人': 413,\n",
       " '궁금증': 414,\n",
       " '사단장': 415,\n",
       " 'Sic': 416,\n",
       " '격변기': 417,\n",
       " '아처': 418,\n",
       " '申': 419,\n",
       " '노건평': 420,\n",
       " '삼복중': 421,\n",
       " '쥔': 422,\n",
       " '미루': 423,\n",
       " '베테': 424,\n",
       " '干': 425,\n",
       " '중학생': 426,\n",
       " '이동인': 427,\n",
       " 'Since': 428,\n",
       " '시그널': 429,\n",
       " '觸': 430,\n",
       " '남초': 431,\n",
       " '오미야': 432,\n",
       " 'Island': 433,\n",
       " '격차': 434,\n",
       " '불모지': 435,\n",
       " 'MQA': 436,\n",
       " '사회복음주의': 437,\n",
       " '칼튼': 438,\n",
       " '지글러': 439,\n",
       " '요나스': 440,\n",
       " '맞춰서': 441,\n",
       " '新舊': 442,\n",
       " '틸': 443,\n",
       " '콘스탄티우스': 444,\n",
       " '사황': 445,\n",
       " '여비서': 446,\n",
       " '침감': 447,\n",
       " '전입자': 448,\n",
       " '굳세': 449,\n",
       " '중강진': 450,\n",
       " '박석민': 451,\n",
       " '견갑': 452,\n",
       " 'gangway': 453,\n",
       " '스폴': 454,\n",
       " 'Treptow': 455,\n",
       " '만마': 456,\n",
       " '성광': 457,\n",
       " '소지섭': 458,\n",
       " '남류': 459,\n",
       " '익산': 460,\n",
       " '전보국': 461,\n",
       " '봇물': 462,\n",
       " '크레셴도': 463,\n",
       " 'fuzzy': 464,\n",
       " '시나가와': 465,\n",
       " '나쁠': 466,\n",
       " '사마': 467,\n",
       " '모른': 468,\n",
       " '흑요석': 469,\n",
       " '흑토': 470,\n",
       " '지치부': 471,\n",
       " '주위염': 472,\n",
       " '줘': 473,\n",
       " '반크': 474,\n",
       " '아르투로': 475,\n",
       " '김순애': 476,\n",
       " '하타': 477,\n",
       " '힉스': 478,\n",
       " '오랫만': 479,\n",
       " '파리스': 480,\n",
       " '역리': 481,\n",
       " '거명': 482,\n",
       " '평화재단': 483,\n",
       " '짠맛': 484,\n",
       " 'Essex': 485,\n",
       " '사우스오스트레일리아': 486,\n",
       " '체강': 487,\n",
       " '당한': 488,\n",
       " '들으려': 489,\n",
       " '사안': 490,\n",
       " '게이고': 491,\n",
       " '노무라': 492,\n",
       " '기본요금': 493,\n",
       " '결승전': 494,\n",
       " '정치권력': 495,\n",
       " 'comitia': 496,\n",
       " 'tinnunculus': 497,\n",
       " '성장': 498,\n",
       " '포진지': 499,\n",
       " '플라우투스': 500,\n",
       " '요시무네': 501,\n",
       " 'Bells': 502,\n",
       " '충정왕': 503,\n",
       " '김태영': 504,\n",
       " 'Sniper': 505,\n",
       " 'Elliott': 506,\n",
       " '스타팅': 507,\n",
       " '승객': 508,\n",
       " '김석준': 509,\n",
       " 'Leben': 510,\n",
       " '만석': 511,\n",
       " '불순분자': 512,\n",
       " '더시': 513,\n",
       " '諸家': 514,\n",
       " '배넌': 515,\n",
       " '카자흐스탄': 516,\n",
       " 'strength': 517,\n",
       " '게놈': 518,\n",
       " '중앙청': 519,\n",
       " 'Traveling': 520,\n",
       " 'afternoon': 521,\n",
       " '날인': 522,\n",
       " '항법': 523,\n",
       " '역차별': 524,\n",
       " '저명인사': 525,\n",
       " '더스크': 526,\n",
       " '연후': 527,\n",
       " 'fibre': 528,\n",
       " '안사리': 529,\n",
       " '코스모': 530,\n",
       " '보험료': 531,\n",
       " '끌어올리': 532,\n",
       " '대음극': 533,\n",
       " '부딪힐': 534,\n",
       " '海面': 535,\n",
       " '덴': 536,\n",
       " '마쓰오': 537,\n",
       " '안재홍': 538,\n",
       " '실리콘밸리': 539,\n",
       " 'LM': 540,\n",
       " '검사정': 541,\n",
       " 'SUA': 542,\n",
       " '가와고에': 543,\n",
       " '뒤': 544,\n",
       " '게이스케': 545,\n",
       " \"...'\": 546,\n",
       " '是是非非': 547,\n",
       " 'community': 548,\n",
       " '裕': 549,\n",
       " '조산': 550,\n",
       " '지학': 551,\n",
       " '이탈리아어': 552,\n",
       " '시녀': 553,\n",
       " '갈비뼈': 554,\n",
       " '대전제': 555,\n",
       " '人道': 556,\n",
       " '수춘': 557,\n",
       " '스피커': 558,\n",
       " '개별': 559,\n",
       " '삼성카드': 560,\n",
       " '은박지': 561,\n",
       " '내려줄': 562,\n",
       " '문기': 563,\n",
       " 'Haig': 564,\n",
       " '해감': 565,\n",
       " 'Carigali': 566,\n",
       " '박미옥': 567,\n",
       " '뱀상어': 568,\n",
       " '동방견문록': 569,\n",
       " '비행대': 570,\n",
       " '슈말칼덴': 571,\n",
       " '해설': 572,\n",
       " '일음': 573,\n",
       " '무현': 574,\n",
       " '림스키코르사코프': 575,\n",
       " '경매': 576,\n",
       " 'BangTan': 577,\n",
       " '학보': 578,\n",
       " '피진': 579,\n",
       " '煙': 580,\n",
       " '극한값': 581,\n",
       " '연공': 582,\n",
       " '이마트': 583,\n",
       " '活': 584,\n",
       " '누른': 585,\n",
       " '배부': 586,\n",
       " '알아듣': 587,\n",
       " '신칸센': 588,\n",
       " '맞싸우': 589,\n",
       " '제수': 590,\n",
       " '자동자': 591,\n",
       " 'Powell': 592,\n",
       " '이종웅': 593,\n",
       " '선셋': 594,\n",
       " 'ة': 595,\n",
       " 'Schröder': 596,\n",
       " 'Mariah': 597,\n",
       " '지워': 598,\n",
       " '야마가타': 599,\n",
       " '귀한': 600,\n",
       " '선분': 601,\n",
       " '오호': 602,\n",
       " '따스': 603,\n",
       " '악대': 604,\n",
       " '공손': 605,\n",
       " '선자': 606,\n",
       " '노히메': 607,\n",
       " '심혈': 608,\n",
       " '심폐': 609,\n",
       " '이제훈': 610,\n",
       " '덜컥': 611,\n",
       " '스페인령': 612,\n",
       " '한국은행': 613,\n",
       " '조상제': 614,\n",
       " '김상': 615,\n",
       " '압출': 616,\n",
       " 'Napoleon': 617,\n",
       " '초의': 618,\n",
       " '주입': 619,\n",
       " '한양여자대학': 620,\n",
       " '대전투': 621,\n",
       " '중앙역': 622,\n",
       " '니컬러스': 623,\n",
       " '오대륙': 624,\n",
       " '옛날': 625,\n",
       " '지배층': 626,\n",
       " '패전': 627,\n",
       " '하딩': 628,\n",
       " '브로니슬라브': 629,\n",
       " '홈피': 630,\n",
       " '궤양': 631,\n",
       " '에두아르': 632,\n",
       " '루팡': 633,\n",
       " '자제': 634,\n",
       " '히메지': 635,\n",
       " '란자': 636,\n",
       " '遺失': 637,\n",
       " '유웅': 638,\n",
       " '내리친': 639,\n",
       " 'Resist': 640,\n",
       " 'Ground': 641,\n",
       " '고졸': 642,\n",
       " '우먼': 643,\n",
       " '총구': 644,\n",
       " '推擧': 645,\n",
       " '인관': 646,\n",
       " '야마나카': 647,\n",
       " '원로원': 648,\n",
       " '서스쿼해나': 649,\n",
       " '조옥': 650,\n",
       " '러브굿': 651,\n",
       " '김광림': 652,\n",
       " 'AFL': 653,\n",
       " 'photosensitive': 654,\n",
       " '능이': 655,\n",
       " '들이붓': 656,\n",
       " '나루터': 657,\n",
       " '친필': 658,\n",
       " '正文': 659,\n",
       " '지난다': 660,\n",
       " '에피고노이': 661,\n",
       " '호응': 662,\n",
       " '조진': 663,\n",
       " '종기': 664,\n",
       " 'McCarthy': 665,\n",
       " '악폐': 666,\n",
       " '불심': 667,\n",
       " '기간제': 668,\n",
       " '스칼렛': 669,\n",
       " '스콜라': 670,\n",
       " '강진': 671,\n",
       " '굴러떨어진': 672,\n",
       " '바카리': 673,\n",
       " '랍시고': 674,\n",
       " '드나드': 675,\n",
       " '앞서': 676,\n",
       " '부담감': 677,\n",
       " '금리정책': 678,\n",
       " '쓰임': 679,\n",
       " '한상봉': 680,\n",
       " '시리얼': 681,\n",
       " '레소토': 682,\n",
       " '정보력': 683,\n",
       " '보정': 684,\n",
       " '행어': 685,\n",
       " '끈기': 686,\n",
       " '위기관리': 687,\n",
       " '마호가니': 688,\n",
       " '스터너': 689,\n",
       " '지박': 690,\n",
       " '일설': 691,\n",
       " '발렌시아': 692,\n",
       " 'Corps': 693,\n",
       " '이아시': 694,\n",
       " '업계': 695,\n",
       " '너트': 696,\n",
       " '육상산': 697,\n",
       " '앉': 698,\n",
       " 'rain': 699,\n",
       " '입진': 700,\n",
       " '설계가': 701,\n",
       " '셀틱스': 702,\n",
       " '분소': 703,\n",
       " '퍼매너': 704,\n",
       " '易姓': 705,\n",
       " '소설책': 706,\n",
       " '새크라멘토': 707,\n",
       " '시보레': 708,\n",
       " '庵': 709,\n",
       " '회전익': 710,\n",
       " '마미': 711,\n",
       " '포워드': 712,\n",
       " '직결': 713,\n",
       " '해군기': 714,\n",
       " '회상': 715,\n",
       " '에필로그': 716,\n",
       " 'selection': 717,\n",
       " '타이론': 718,\n",
       " '미스터피자': 719,\n",
       " '어치': 720,\n",
       " 'Bertrand': 721,\n",
       " '多羅': 722,\n",
       " '강비': 723,\n",
       " '대함': 724,\n",
       " 'Rick': 725,\n",
       " '모계': 726,\n",
       " '권한': 727,\n",
       " '정릉동': 728,\n",
       " '르메이': 729,\n",
       " '정객': 730,\n",
       " '전투대': 731,\n",
       " '웽': 732,\n",
       " '뒤마': 733,\n",
       " '놀트': 734,\n",
       " '민회': 735,\n",
       " '십수': 736,\n",
       " '탐스': 737,\n",
       " 'mathematics': 738,\n",
       " '이등병': 739,\n",
       " '풀밭': 740,\n",
       " 'Electoral': 741,\n",
       " '병산': 742,\n",
       " '관북리': 743,\n",
       " '이발기': 744,\n",
       " 'NRW': 745,\n",
       " '각양각색': 746,\n",
       " '보더': 747,\n",
       " '오르내렸': 748,\n",
       " '돼버렸': 749,\n",
       " '피치블렌드': 750,\n",
       " '통각': 751,\n",
       " '임할': 752,\n",
       " '馬': 753,\n",
       " '고고도': 754,\n",
       " '쥬얼리': 755,\n",
       " '서기전': 756,\n",
       " '시민법': 757,\n",
       " '청슬': 758,\n",
       " '이기동': 759,\n",
       " '시외': 760,\n",
       " '長春': 761,\n",
       " '함종': 762,\n",
       " 'Leslie': 763,\n",
       " '글로벌': 764,\n",
       " '거닐': 765,\n",
       " '命': 766,\n",
       " '보이즈': 767,\n",
       " '김필순': 768,\n",
       " '결의': 769,\n",
       " '대자동': 770,\n",
       " '이회관': 771,\n",
       " '도왔': 772,\n",
       " '衛將': 773,\n",
       " '소회': 774,\n",
       " 'non': 775,\n",
       " '가까이': 776,\n",
       " '에드워드': 777,\n",
       " '물려줬': 778,\n",
       " '彭': 779,\n",
       " '도로포장': 780,\n",
       " 'democracy': 781,\n",
       " '만듦으로써': 782,\n",
       " '용차': 783,\n",
       " '존중': 784,\n",
       " '電位': 785,\n",
       " '양아버지': 786,\n",
       " '革新': 787,\n",
       " '인회': 788,\n",
       " '문재인': 789,\n",
       " '게링': 790,\n",
       " '선약': 791,\n",
       " '안녕질서': 792,\n",
       " '거북': 793,\n",
       " '楫': 794,\n",
       " '서핑': 795,\n",
       " '슈웨다곤': 796,\n",
       " 'あなただけが': 797,\n",
       " '압구정동': 798,\n",
       " '짓눌리': 799,\n",
       " '들여보낸': 800,\n",
       " '누수': 801,\n",
       " 'Táin': 802,\n",
       " '반하': 803,\n",
       " '축구팀': 804,\n",
       " '터번': 805,\n",
       " 'Hadik': 806,\n",
       " '누설': 807,\n",
       " '소르': 808,\n",
       " 'ㅡ한': 809,\n",
       " '아체': 810,\n",
       " '단주기': 811,\n",
       " 'Comme': 812,\n",
       " '사라졌': 813,\n",
       " '수륙': 814,\n",
       " '성절사': 815,\n",
       " '닥쳤': 816,\n",
       " '나지': 817,\n",
       " '양문': 818,\n",
       " '폴리머': 819,\n",
       " '법정형': 820,\n",
       " '테네시주': 821,\n",
       " '브레메': 822,\n",
       " '아닥스': 823,\n",
       " '곁': 824,\n",
       " '스틸웰': 825,\n",
       " '야스지': 826,\n",
       " 'exaltation': 827,\n",
       " '둔상': 828,\n",
       " '경쟁력': 829,\n",
       " '음경골': 830,\n",
       " '石': 831,\n",
       " '어게인': 832,\n",
       " '의친왕': 833,\n",
       " '다우니': 834,\n",
       " '측량사': 835,\n",
       " '배사': 836,\n",
       " '김가연': 837,\n",
       " '회의장': 838,\n",
       " '네브래스카': 839,\n",
       " 'cooping': 840,\n",
       " '종이학': 841,\n",
       " '부사이나': 842,\n",
       " '돌파력': 843,\n",
       " '양평': 844,\n",
       " '남중': 845,\n",
       " 'GABA': 846,\n",
       " '모멘트': 847,\n",
       " '시화': 848,\n",
       " '기당': 849,\n",
       " '워진': 850,\n",
       " '제럴드': 851,\n",
       " '율리히': 852,\n",
       " '극동방송': 853,\n",
       " '塡': 854,\n",
       " '別子': 855,\n",
       " '코스튬': 856,\n",
       " '수총': 857,\n",
       " '쥐코': 858,\n",
       " 'unz': 859,\n",
       " '연정훈': 860,\n",
       " '만': 861,\n",
       " '홍구': 862,\n",
       " '한모': 863,\n",
       " '당초': 864,\n",
       " '하': 865,\n",
       " '입안': 866,\n",
       " 'Campaign': 867,\n",
       " '경제학상': 868,\n",
       " 'Use': 869,\n",
       " '휴교령': 870,\n",
       " '무도장': 871,\n",
       " '하도': 872,\n",
       " '강동': 873,\n",
       " '오비슨': 874,\n",
       " 'Sulpicius': 875,\n",
       " '김창완': 876,\n",
       " '들으니': 877,\n",
       " '의용': 878,\n",
       " '細分': 879,\n",
       " 'surprisingly': 880,\n",
       " '리조': 881,\n",
       " 'structuralist': 882,\n",
       " '망설임': 883,\n",
       " '성권': 884,\n",
       " '콘스탄티누스': 885,\n",
       " '口宣': 886,\n",
       " '해로가': 887,\n",
       " 'most': 888,\n",
       " '영상분': 889,\n",
       " '사격장': 890,\n",
       " '프롬스': 891,\n",
       " '태학': 892,\n",
       " '폴리비닐': 893,\n",
       " '사실주의': 894,\n",
       " '거란': 895,\n",
       " '내일': 896,\n",
       " '개종자': 897,\n",
       " '스': 898,\n",
       " '농대': 899,\n",
       " '이치현': 900,\n",
       " '후백': 901,\n",
       " '記': 902,\n",
       " 'Clyde': 903,\n",
       " 'mo': 904,\n",
       " 'Leoben': 905,\n",
       " 'THEIR': 906,\n",
       " '끼웠': 907,\n",
       " '석기': 908,\n",
       " '이광': 909,\n",
       " '박탈': 910,\n",
       " '브롤린': 911,\n",
       " '이관': 912,\n",
       " '드라': 913,\n",
       " '모터': 914,\n",
       " 'Cuoco': 915,\n",
       " '깃들': 916,\n",
       " '찬탁': 917,\n",
       " '길리안': 918,\n",
       " '양성현': 919,\n",
       " '산토로': 920,\n",
       " '정출': 921,\n",
       " '마츠다': 922,\n",
       " '앞마당': 923,\n",
       " '총파업': 924,\n",
       " '이혼녀': 925,\n",
       " 'Chur': 926,\n",
       " 'Carnegie': 927,\n",
       " '텐데요': 928,\n",
       " '위구르': 929,\n",
       " '주머니칼': 930,\n",
       " '환경부': 931,\n",
       " '동무': 932,\n",
       " '호즈미': 933,\n",
       " '스코리아': 934,\n",
       " '信心': 935,\n",
       " '조스케': 936,\n",
       " '불어나': 937,\n",
       " 'Rojo': 938,\n",
       " '델리아': 939,\n",
       " '경관': 940,\n",
       " '엘리아스': 941,\n",
       " '박목월': 942,\n",
       " '엘리': 943,\n",
       " 'Begin': 944,\n",
       " '전라남도': 945,\n",
       " '수하': 946,\n",
       " '각목': 947,\n",
       " '대응': 948,\n",
       " '희소성': 949,\n",
       " '면식': 950,\n",
       " '자사': 951,\n",
       " 'propeller': 952,\n",
       " '중매인': 953,\n",
       " '알린': 954,\n",
       " 'MIDEM': 955,\n",
       " '철학자': 956,\n",
       " '누린다': 957,\n",
       " 'gallinae': 958,\n",
       " 'Denominazione': 959,\n",
       " '가평': 960,\n",
       " '추진력': 961,\n",
       " '로스엔젤레스': 962,\n",
       " '무예': 963,\n",
       " '興': 964,\n",
       " '장티푸스': 965,\n",
       " '마리나': 966,\n",
       " '개거': 967,\n",
       " 'stroboscope': 968,\n",
       " '는데요': 969,\n",
       " 'Usher': 970,\n",
       " '무라': 971,\n",
       " '김꽃비': 972,\n",
       " '블로킹': 973,\n",
       " 'miltare': 974,\n",
       " '쿨타임': 975,\n",
       " '배터리': 976,\n",
       " '한국교육개발원': 977,\n",
       " 'Maalum': 978,\n",
       " '성인병': 979,\n",
       " '부스럼': 980,\n",
       " '윤지': 981,\n",
       " '배달': 982,\n",
       " '채시라': 983,\n",
       " '대우': 984,\n",
       " 'Considérations': 985,\n",
       " '准': 986,\n",
       " 'Billboard': 987,\n",
       " '베르길리우스': 988,\n",
       " '타벨': 989,\n",
       " '이야': 990,\n",
       " '웃음기': 991,\n",
       " '압구정': 992,\n",
       " '산란장': 993,\n",
       " '릭시': 994,\n",
       " 'Alexeiev': 995,\n",
       " '부설': 996,\n",
       " '경솔': 997,\n",
       " '에따': 998,\n",
       " '인질': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = []\n",
    "for word in word_to_id.keys():\n",
    "    id_to_word.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터를 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(corpus)):\n",
    "    train_data += sent_to_ngram(N, corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '8', '3', '9'],\n",
       " ['8', '3', '9', '년'],\n",
       " ['3', '9', '년', '바그너'],\n",
       " ['9', '년', '바그너', '는'],\n",
       " ['년', '바그너', '는', '괴테'],\n",
       " ['바그너', '는', '괴테', '의'],\n",
       " ['는', '괴테', '의', '파우스트'],\n",
       " ['괴테', '의', '파우스트', '을'],\n",
       " ['의', '파우스트', '을', '처음'],\n",
       " ['파우스트', '을', '처음', '읽'],\n",
       " ['을', '처음', '읽', '고'],\n",
       " ['처음', '읽', '고', '그'],\n",
       " ['읽', '고', '그', '내용'],\n",
       " ['고', '그', '내용', '에'],\n",
       " ['그', '내용', '에', '마음'],\n",
       " ['내용', '에', '마음', '이'],\n",
       " ['에', '마음', '이', '끌려'],\n",
       " ['마음', '이', '끌려', '이'],\n",
       " ['이', '끌려', '이', '를'],\n",
       " ['끌려', '이', '를', '소재'],\n",
       " ['이', '를', '소재', '로'],\n",
       " ['를', '소재', '로', '해서'],\n",
       " ['소재', '로', '해서', '하나'],\n",
       " ['로', '해서', '하나', '의'],\n",
       " ['해서', '하나', '의', '교향곡'],\n",
       " ['하나', '의', '교향곡', '을'],\n",
       " ['의', '교향곡', '을', '쓰'],\n",
       " ['교향곡', '을', '쓰', '려는'],\n",
       " ['을', '쓰', '려는', '뜻'],\n",
       " ['쓰', '려는', '뜻', '을'],\n",
       " ['려는', '뜻', '을', '갖'],\n",
       " ['뜻', '을', '갖', '는다'],\n",
       " ['을', '갖', '는다', '.'],\n",
       " ['갖', '는다', '.', '이'],\n",
       " ['는다', '.', '이', '시기'],\n",
       " ['.', '이', '시기', '바그너'],\n",
       " ['이', '시기', '바그너', '는'],\n",
       " ['시기', '바그너', '는', '1'],\n",
       " ['바그너', '는', '1', '8'],\n",
       " ['는', '1', '8', '3'],\n",
       " ['1', '8', '3', '8'],\n",
       " ['8', '3', '8', '년'],\n",
       " ['3', '8', '년', '에'],\n",
       " ['8', '년', '에', '빛'],\n",
       " ['년', '에', '빛', '독촉'],\n",
       " ['에', '빛', '독촉', '으로'],\n",
       " ['빛', '독촉', '으로', '산전수전'],\n",
       " ['독촉', '으로', '산전수전', '을'],\n",
       " ['으로', '산전수전', '을', '다'],\n",
       " ['산전수전', '을', '다', '걲은'],\n",
       " ['을', '다', '걲은', '상황'],\n",
       " ['다', '걲은', '상황', '이'],\n",
       " ['걲은', '상황', '이', '라'],\n",
       " ['상황', '이', '라', '좌절'],\n",
       " ['이', '라', '좌절', '과'],\n",
       " ['라', '좌절', '과', '실망'],\n",
       " ['좌절', '과', '실망', '에'],\n",
       " ['과', '실망', '에', '가득'],\n",
       " ['실망', '에', '가득', '했으며'],\n",
       " ['에', '가득', '했으며', '메피스토펠레스'],\n",
       " ['가득', '했으며', '메피스토펠레스', '를'],\n",
       " ['했으며', '메피스토펠레스', '를', '만나'],\n",
       " ['메피스토펠레스', '를', '만나', '는'],\n",
       " ['를', '만나', '는', '파우스트'],\n",
       " ['만나', '는', '파우스트', '의'],\n",
       " ['는', '파우스트', '의', '심경'],\n",
       " ['파우스트', '의', '심경', '에'],\n",
       " ['의', '심경', '에', '공감'],\n",
       " ['심경', '에', '공감', '했'],\n",
       " ['에', '공감', '했', '다고'],\n",
       " ['공감', '했', '다고', '한다'],\n",
       " ['했', '다고', '한다', '.'],\n",
       " ['다고', '한다', '.', '또한'],\n",
       " ['한다', '.', '또한', '파리'],\n",
       " ['.', '또한', '파리', '에서'],\n",
       " ['또한', '파리', '에서', '아'],\n",
       " ['파리', '에서', '아', '브네'],\n",
       " ['에서', '아', '브네', '크'],\n",
       " ['아', '브네', '크', '의'],\n",
       " ['브네', '크', '의', '지휘'],\n",
       " ['크', '의', '지휘', '로'],\n",
       " ['의', '지휘', '로', '파리'],\n",
       " ['지휘', '로', '파리', '음악원'],\n",
       " ['로', '파리', '음악원', '관현악단'],\n",
       " ['파리', '음악원', '관현악단', '이'],\n",
       " ['음악원', '관현악단', '이', '연주'],\n",
       " ['관현악단', '이', '연주', '하'],\n",
       " ['이', '연주', '하', '는'],\n",
       " ['연주', '하', '는', '베토벤'],\n",
       " ['하', '는', '베토벤', '의'],\n",
       " ['는', '베토벤', '의', '교향곡'],\n",
       " ['베토벤', '의', '교향곡', '9'],\n",
       " ['의', '교향곡', '9', '번'],\n",
       " ['교향곡', '9', '번', '을'],\n",
       " ['9', '번', '을', '듣'],\n",
       " ['번', '을', '듣', '고'],\n",
       " ['을', '듣', '고', '깊'],\n",
       " ['듣', '고', '깊', '은'],\n",
       " ['고', '깊', '은', '감명'],\n",
       " ['깊', '은', '감명', '을'],\n",
       " ['은', '감명', '을', '받'],\n",
       " ['감명', '을', '받', '았'],\n",
       " ['을', '받', '았', '는데'],\n",
       " ['받', '았', '는데', ','],\n",
       " ['았', '는데', ',', '이것'],\n",
       " ['는데', ',', '이것', '이'],\n",
       " [',', '이것', '이', '이듬해'],\n",
       " ['이것', '이', '이듬해', '1'],\n",
       " ['이', '이듬해', '1', '월'],\n",
       " ['이듬해', '1', '월', '에'],\n",
       " ['1', '월', '에', '파우스트'],\n",
       " ['월', '에', '파우스트', '의'],\n",
       " ['에', '파우스트', '의', '서곡'],\n",
       " ['파우스트', '의', '서곡', '으로'],\n",
       " ['의', '서곡', '으로', '쓰여진'],\n",
       " ['서곡', '으로', '쓰여진', '이'],\n",
       " ['으로', '쓰여진', '이', '작품'],\n",
       " ['쓰여진', '이', '작품', '에'],\n",
       " ['이', '작품', '에', '조금'],\n",
       " ['작품', '에', '조금', '이'],\n",
       " ['에', '조금', '이', '라도'],\n",
       " ['조금', '이', '라도', '영향'],\n",
       " ['이', '라도', '영향', '을'],\n",
       " ['라도', '영향', '을', '끼쳤'],\n",
       " ['영향', '을', '끼쳤', '으리라는'],\n",
       " ['을', '끼쳤', '으리라는', '것'],\n",
       " ['끼쳤', '으리라는', '것', '은'],\n",
       " ['으리라는', '것', '은', '의심'],\n",
       " ['것', '은', '의심', '할'],\n",
       " ['은', '의심', '할', '여지'],\n",
       " ['의심', '할', '여지', '가'],\n",
       " ['할', '여지', '가', '없'],\n",
       " ['여지', '가', '없', '다'],\n",
       " ['가', '없', '다', '.'],\n",
       " ['없', '다', '.', '여기'],\n",
       " ['다', '.', '여기', '의'],\n",
       " ['.', '여기', '의', '라단조'],\n",
       " ['여기', '의', '라단조', '조성'],\n",
       " ['의', '라단조', '조성', '의'],\n",
       " ['라단조', '조성', '의', '경우'],\n",
       " ['조성', '의', '경우', '에'],\n",
       " ['의', '경우', '에', '도'],\n",
       " ['경우', '에', '도', '그'],\n",
       " ['에', '도', '그', '의'],\n",
       " ['도', '그', '의', '전기'],\n",
       " ['그', '의', '전기', '에'],\n",
       " ['의', '전기', '에', '적혀'],\n",
       " ['전기', '에', '적혀', '있'],\n",
       " ['에', '적혀', '있', '는'],\n",
       " ['적혀', '있', '는', '것'],\n",
       " ['있', '는', '것', '처럼'],\n",
       " ['는', '것', '처럼', '단순'],\n",
       " ['것', '처럼', '단순', '한'],\n",
       " ['처럼', '단순', '한', '정신'],\n",
       " ['단순', '한', '정신', '적'],\n",
       " ['한', '정신', '적', '피로'],\n",
       " ['정신', '적', '피로', '나'],\n",
       " ['적', '피로', '나', '실의'],\n",
       " ['피로', '나', '실의', '가'],\n",
       " ['나', '실의', '가', '반영'],\n",
       " ['실의', '가', '반영', '된'],\n",
       " ['가', '반영', '된', '것'],\n",
       " ['반영', '된', '것', '이'],\n",
       " ['된', '것', '이', '아니'],\n",
       " ['것', '이', '아니', '라'],\n",
       " ['이', '아니', '라', '베토벤'],\n",
       " ['아니', '라', '베토벤', '의'],\n",
       " ['라', '베토벤', '의', '합창'],\n",
       " ['베토벤', '의', '합창', '교향곡'],\n",
       " ['의', '합창', '교향곡', '조성'],\n",
       " ['합창', '교향곡', '조성', '의'],\n",
       " ['교향곡', '조성', '의', '영향'],\n",
       " ['조성', '의', '영향', '을'],\n",
       " ['의', '영향', '을', '받'],\n",
       " ['영향', '을', '받', '은'],\n",
       " ['을', '받', '은', '것'],\n",
       " ['받', '은', '것', '을'],\n",
       " ['은', '것', '을', '볼'],\n",
       " ['것', '을', '볼', '수'],\n",
       " ['을', '볼', '수', '있'],\n",
       " ['볼', '수', '있', '다'],\n",
       " ['수', '있', '다', '.'],\n",
       " ['있', '다', '.', '그렇게'],\n",
       " ['다', '.', '그렇게', '교향곡'],\n",
       " ['.', '그렇게', '교향곡', '작곡'],\n",
       " ['그렇게', '교향곡', '작곡', '을'],\n",
       " ['교향곡', '작곡', '을', '1'],\n",
       " ['작곡', '을', '1', '8'],\n",
       " ['을', '1', '8', '3'],\n",
       " ['1', '8', '3', '9'],\n",
       " ['8', '3', '9', '년'],\n",
       " ['3', '9', '년', '부터'],\n",
       " ['9', '년', '부터', '4'],\n",
       " ['년', '부터', '4', '0'],\n",
       " ['부터', '4', '0', '년'],\n",
       " ['4', '0', '년', '에'],\n",
       " ['0', '년', '에', '걸쳐'],\n",
       " ['년', '에', '걸쳐', '파리'],\n",
       " ['에', '걸쳐', '파리', '에서'],\n",
       " ['걸쳐', '파리', '에서', '착수'],\n",
       " ['파리', '에서', '착수', '했으나'],\n",
       " ['에서', '착수', '했으나', '1'],\n",
       " ['착수', '했으나', '1', '악장'],\n",
       " ['했으나', '1', '악장', '을'],\n",
       " ['1', '악장', '을', '쓴'],\n",
       " ['악장', '을', '쓴', '뒤'],\n",
       " ['을', '쓴', '뒤', '에'],\n",
       " ['쓴', '뒤', '에', '중단'],\n",
       " ['뒤', '에', '중단', '했'],\n",
       " ['에', '중단', '했', '다'],\n",
       " ['중단', '했', '다', '.'],\n",
       " ['했', '다', '.', '또한'],\n",
       " ['다', '.', '또한', '작품'],\n",
       " ['.', '또한', '작품', '의'],\n",
       " ['또한', '작품', '의', '완성'],\n",
       " ['작품', '의', '완성', '과'],\n",
       " ['의', '완성', '과', '동시'],\n",
       " ['완성', '과', '동시', '에'],\n",
       " ['과', '동시', '에', '그'],\n",
       " ['동시', '에', '그', '는'],\n",
       " ['에', '그', '는', '이'],\n",
       " ['그', '는', '이', '서곡'],\n",
       " ['는', '이', '서곡', '('],\n",
       " ['이', '서곡', '(', '1'],\n",
       " ['서곡', '(', '1', '악장'],\n",
       " ['(', '1', '악장', ')'],\n",
       " ['1', '악장', ')', '을'],\n",
       " ['악장', ')', '을', '파리'],\n",
       " [')', '을', '파리', '음악원'],\n",
       " ['을', '파리', '음악원', '의'],\n",
       " ['파리', '음악원', '의', '연주회'],\n",
       " ['음악원', '의', '연주회', '에서'],\n",
       " ['의', '연주회', '에서', '연주'],\n",
       " ['연주회', '에서', '연주', '할'],\n",
       " ['에서', '연주', '할', '파트'],\n",
       " ['연주', '할', '파트', '보'],\n",
       " ['할', '파트', '보', '까지'],\n",
       " ['파트', '보', '까지', '준비'],\n",
       " ['보', '까지', '준비', '하'],\n",
       " ['까지', '준비', '하', '였으나'],\n",
       " ['준비', '하', '였으나', ','],\n",
       " ['하', '였으나', ',', '실제로'],\n",
       " ['였으나', ',', '실제로', '는'],\n",
       " [',', '실제로', '는', '이루'],\n",
       " ['실제로', '는', '이루', '어'],\n",
       " ['는', '이루', '어', '지지'],\n",
       " ['이루', '어', '지지', '는'],\n",
       " ['어', '지지', '는', '않'],\n",
       " ['지지', '는', '않', '았'],\n",
       " ['는', '않', '았', '다'],\n",
       " ['않', '았', '다', '.'],\n",
       " ['았', '다', '.', '결국'],\n",
       " ['다', '.', '결국', '초연'],\n",
       " ['.', '결국', '초연', '은'],\n",
       " ['결국', '초연', '은', '4'],\n",
       " ['초연', '은', '4', '년'],\n",
       " ['은', '4', '년', '반'],\n",
       " ['4', '년', '반', '이'],\n",
       " ['년', '반', '이', '지난'],\n",
       " ['반', '이', '지난', '후'],\n",
       " ['이', '지난', '후', '에'],\n",
       " ['지난', '후', '에', '드레스덴'],\n",
       " ['후', '에', '드레스덴', '에서'],\n",
       " ['에', '드레스덴', '에서', '연주'],\n",
       " ['드레스덴', '에서', '연주', '되'],\n",
       " ['에서', '연주', '되', '었'],\n",
       " ['연주', '되', '었', '고'],\n",
       " ['되', '었', '고', '재연'],\n",
       " ['었', '고', '재연', '도'],\n",
       " ['고', '재연', '도', '이루'],\n",
       " ['재연', '도', '이루', '어'],\n",
       " ['도', '이루', '어', '졌'],\n",
       " ['이루', '어', '졌', '지만'],\n",
       " ['어', '졌', '지만', ','],\n",
       " ['졌', '지만', ',', '이후'],\n",
       " ['지만', ',', '이후', '에'],\n",
       " [',', '이후', '에', '그대로'],\n",
       " ['이후', '에', '그대로', '방치'],\n",
       " ['에', '그대로', '방치', '되'],\n",
       " ['그대로', '방치', '되', '고'],\n",
       " ['방치', '되', '고', '말'],\n",
       " ['되', '고', '말', '았'],\n",
       " ['고', '말', '았', '다'],\n",
       " ['말', '았', '다', '.'],\n",
       " ['았', '다', '.', '그'],\n",
       " ['다', '.', '그', '사이'],\n",
       " ['.', '그', '사이', '에'],\n",
       " ['그', '사이', '에', '그'],\n",
       " ['사이', '에', '그', '는'],\n",
       " ['에', '그', '는', '리엔치'],\n",
       " ['그', '는', '리엔치', '와'],\n",
       " ['는', '리엔치', '와', '방황'],\n",
       " ['리엔치', '와', '방황', '하'],\n",
       " ['와', '방황', '하', '는'],\n",
       " ['방황', '하', '는', '네덜란드인'],\n",
       " ['하', '는', '네덜란드인', '을'],\n",
       " ['는', '네덜란드인', '을', '완성'],\n",
       " ['네덜란드인', '을', '완성', '하'],\n",
       " ['을', '완성', '하', '고'],\n",
       " ['완성', '하', '고', '탄호이저'],\n",
       " ['하', '고', '탄호이저', '에'],\n",
       " ['고', '탄호이저', '에', '도'],\n",
       " ['탄호이저', '에', '도', '착수'],\n",
       " ['에', '도', '착수', '하'],\n",
       " ['도', '착수', '하', '는'],\n",
       " ['착수', '하', '는', '등'],\n",
       " ['하', '는', '등', '분주'],\n",
       " ['는', '등', '분주', '한'],\n",
       " ['등', '분주', '한', '시간'],\n",
       " ['분주', '한', '시간', '을'],\n",
       " ['한', '시간', '을', '보냈'],\n",
       " ['시간', '을', '보냈', '는데'],\n",
       " ['을', '보냈', '는데', ','],\n",
       " ['보냈', '는데', ',', '그런'],\n",
       " ['는데', ',', '그런', '바쁜'],\n",
       " [',', '그런', '바쁜', '생활'],\n",
       " ['그런', '바쁜', '생활', '이'],\n",
       " ['바쁜', '생활', '이', '이'],\n",
       " ['생활', '이', '이', '곡'],\n",
       " ['이', '이', '곡', '을'],\n",
       " ['이', '곡', '을', '잊'],\n",
       " ['곡', '을', '잊', '게'],\n",
       " ['을', '잊', '게', '한'],\n",
       " ['잊', '게', '한', '것'],\n",
       " ['게', '한', '것', '이'],\n",
       " ['한', '것', '이', '아닌가'],\n",
       " ['것', '이', '아닌가', '하'],\n",
       " ['이', '아닌가', '하', '는'],\n",
       " ['아닌가', '하', '는', '의견'],\n",
       " ['하', '는', '의견', '도'],\n",
       " ['는', '의견', '도', '있'],\n",
       " ['의견', '도', '있', '다'],\n",
       " ['도', '있', '다', '.'],\n",
       " ['바그너', '는', '괴테', '의'],\n",
       " ['는', '괴테', '의', '파우스트'],\n",
       " ['괴테', '의', '파우스트', '를'],\n",
       " ['의', '파우스트', '를', '읽'],\n",
       " ['파우스트', '를', '읽', '고'],\n",
       " ['를', '읽', '고', '무엇'],\n",
       " ['읽', '고', '무엇', '을'],\n",
       " ['고', '무엇', '을', '쓰'],\n",
       " ['무엇', '을', '쓰', '고자'],\n",
       " ['을', '쓰', '고자', '했'],\n",
       " ['쓰', '고자', '했', '는가'],\n",
       " ['고자', '했', '는가', '?'],\n",
       " ['했', '는가', '?', '교향곡'],\n",
       " ['바그너', '는', '교향곡', '작곡'],\n",
       " ['는', '교향곡', '작곡', '을'],\n",
       " ['교향곡', '작곡', '을', '어디'],\n",
       " ['작곡', '을', '어디', '까지'],\n",
       " ['을', '어디', '까지', '쓴'],\n",
       " ['어디', '까지', '쓴', '뒤'],\n",
       " ['까지', '쓴', '뒤', '에'],\n",
       " ['쓴', '뒤', '에', '중단'],\n",
       " ['뒤', '에', '중단', '했'],\n",
       " ['에', '중단', '했', '는가'],\n",
       " ['중단', '했', '는가', '?'],\n",
       " ['했', '는가', '?', '1'],\n",
       " ['는가', '?', '1', '악장'],\n",
       " ['바그너', '가', '파우스트', '서곡'],\n",
       " ['가', '파우스트', '서곡', '을'],\n",
       " ['파우스트', '서곡', '을', '쓸'],\n",
       " ['서곡', '을', '쓸', '때'],\n",
       " ['을', '쓸', '때', '어떤'],\n",
       " ['쓸', '때', '어떤', '곡'],\n",
       " ['때', '어떤', '곡', '의'],\n",
       " ['어떤', '곡', '의', '영향'],\n",
       " ['곡', '의', '영향', '을'],\n",
       " ['의', '영향', '을', '받'],\n",
       " ['영향', '을', '받', '았'],\n",
       " ['을', '받', '았', '는가'],\n",
       " ['받', '았', '는가', '?'],\n",
       " ['았', '는가', '?', '베토벤'],\n",
       " ['는가', '?', '베토벤', '의'],\n",
       " ['?', '베토벤', '의', '교향곡'],\n",
       " ['베토벤', '의', '교향곡', '9'],\n",
       " ['의', '교향곡', '9', '번'],\n",
       " ['1', '8', '3', '9'],\n",
       " ['8', '3', '9', '년'],\n",
       " ['3', '9', '년', '바그너'],\n",
       " ['9', '년', '바그너', '가'],\n",
       " ['년', '바그너', '가', '교향곡'],\n",
       " ['바그너', '가', '교향곡', '의'],\n",
       " ['가', '교향곡', '의', '소재'],\n",
       " ['교향곡', '의', '소재', '로'],\n",
       " ['의', '소재', '로', '쓰'],\n",
       " ['소재', '로', '쓰', '려고'],\n",
       " ['로', '쓰', '려고', '했'],\n",
       " ['쓰', '려고', '했', '던'],\n",
       " ['려고', '했', '던', '책'],\n",
       " ['했', '던', '책', '은'],\n",
       " ['던', '책', '은', '?'],\n",
       " ['책', '은', '?', '파우스트'],\n",
       " ['파우스트', '서곡', '의', '라단조'],\n",
       " ['서곡', '의', '라단조', '조성'],\n",
       " ['의', '라단조', '조성', '이'],\n",
       " ['라단조', '조성', '이', '영향'],\n",
       " ['조성', '이', '영향', '을'],\n",
       " ['이', '영향', '을', '받'],\n",
       " ['영향', '을', '받', '은'],\n",
       " ['을', '받', '은', '베토벤'],\n",
       " ['받', '은', '베토벤', '의'],\n",
       " ['은', '베토벤', '의', '곡'],\n",
       " ['베토벤', '의', '곡', '은'],\n",
       " ['의', '곡', '은', '?'],\n",
       " ['곡', '은', '?', '합창'],\n",
       " ['은', '?', '합창', '교향곡'],\n",
       " ['바그너', '가', '파우스트', '를'],\n",
       " ['가', '파우스트', '를', '처음'],\n",
       " ['파우스트', '를', '처음', '으로'],\n",
       " ['를', '처음', '으로', '읽'],\n",
       " ['처음', '으로', '읽', '은'],\n",
       " ['으로', '읽', '은', '년'],\n",
       " ['읽', '은', '년', '도'],\n",
       " ['은', '년', '도', '는'],\n",
       " ['년', '도', '는', '?'],\n",
       " ['도', '는', '?', '1'],\n",
       " ['는', '?', '1', '8'],\n",
       " ['?', '1', '8', '3'],\n",
       " ['1', '8', '3', '9'],\n",
       " ['바그너', '가', '처음', '교향곡'],\n",
       " ['가', '처음', '교향곡', '작곡'],\n",
       " ['처음', '교향곡', '작곡', '을'],\n",
       " ['교향곡', '작곡', '을', '한'],\n",
       " ['작곡', '을', '한', '장소'],\n",
       " ['을', '한', '장소', '는'],\n",
       " ['한', '장소', '는', '?'],\n",
       " ['장소', '는', '?', '파리'],\n",
       " ['바그너', '의', '1', '악장'],\n",
       " ['의', '1', '악장', '의'],\n",
       " ['1', '악장', '의', '초연'],\n",
       " ['악장', '의', '초연', '은'],\n",
       " ['의', '초연', '은', '어디'],\n",
       " ['초연', '은', '어디', '서'],\n",
       " ['은', '어디', '서', '연주'],\n",
       " ['어디', '서', '연주', '되'],\n",
       " ['서', '연주', '되', '었'],\n",
       " ['연주', '되', '었', '는가'],\n",
       " ['되', '었', '는가', '?'],\n",
       " ['었', '는가', '?', '드레스'],\n",
       " ['는가', '?', '드레스', '덴'],\n",
       " ['한편', '1', '8', '4'],\n",
       " ['1', '8', '4', '0'],\n",
       " ['8', '4', '0', '년'],\n",
       " ['4', '0', '년', '부터'],\n",
       " ['0', '년', '부터', '바그너'],\n",
       " ['년', '부터', '바그너', '와'],\n",
       " ['부터', '바그너', '와', '알'],\n",
       " ['바그너', '와', '알', '고'],\n",
       " ['와', '알', '고', '지내'],\n",
       " ['알', '고', '지내', '던'],\n",
       " ['고', '지내', '던', '리스트'],\n",
       " ['지내', '던', '리스트', '가'],\n",
       " ['던', '리스트', '가', '잊혀져'],\n",
       " ['리스트', '가', '잊혀져', '있'],\n",
       " ['가', '잊혀져', '있', '던'],\n",
       " ['잊혀져', '있', '던', '1'],\n",
       " ['있', '던', '1', '악장'],\n",
       " ['던', '1', '악장', '을'],\n",
       " ['1', '악장', '을', '부활'],\n",
       " ['악장', '을', '부활', '시켜'],\n",
       " ['을', '부활', '시켜', '1'],\n",
       " ['부활', '시켜', '1', '8'],\n",
       " ['시켜', '1', '8', '5'],\n",
       " ['1', '8', '5', '2'],\n",
       " ['8', '5', '2', '년'],\n",
       " ['5', '2', '년', '에'],\n",
       " ['2', '년', '에', '바이마르'],\n",
       " ['년', '에', '바이마르', '에서'],\n",
       " ['에', '바이마르', '에서', '연주'],\n",
       " ['바이마르', '에서', '연주', '했'],\n",
       " ['에서', '연주', '했', '다'],\n",
       " ['연주', '했', '다', '.'],\n",
       " ['했', '다', '.', '이것'],\n",
       " ['다', '.', '이것', '을'],\n",
       " ['.', '이것', '을', '계기'],\n",
       " ['이것', '을', '계기', '로'],\n",
       " ['을', '계기', '로', '바그너'],\n",
       " ['계기', '로', '바그너', '도'],\n",
       " ['로', '바그너', '도', '이'],\n",
       " ['바그너', '도', '이', '작품'],\n",
       " ['도', '이', '작품', '에'],\n",
       " ['이', '작품', '에', '다시'],\n",
       " ['작품', '에', '다시', '관심'],\n",
       " ['에', '다시', '관심', '을'],\n",
       " ['다시', '관심', '을', '갖'],\n",
       " ['관심', '을', '갖', '게'],\n",
       " ['을', '갖', '게', '되'],\n",
       " ['갖', '게', '되', '었'],\n",
       " ['게', '되', '었', '고'],\n",
       " ['되', '었', '고', ','],\n",
       " ['었', '고', ',', '그'],\n",
       " ['고', ',', '그', '해'],\n",
       " [',', '그', '해', '9'],\n",
       " ['그', '해', '9', '월'],\n",
       " ['해', '9', '월', '에'],\n",
       " ['9', '월', '에', '는'],\n",
       " ['월', '에', '는', '총보'],\n",
       " ['에', '는', '총보', '의'],\n",
       " ['는', '총보', '의', '반환'],\n",
       " ['총보', '의', '반환', '을'],\n",
       " ['의', '반환', '을', '요구'],\n",
       " ['반환', '을', '요구', '하'],\n",
       " ['을', '요구', '하', '여'],\n",
       " ['요구', '하', '여', '이'],\n",
       " ['하', '여', '이', '를'],\n",
       " ['여', '이', '를', '서곡'],\n",
       " ['이', '를', '서곡', '으로'],\n",
       " ['를', '서곡', '으로', '간추린'],\n",
       " ['서곡', '으로', '간추린', '다음'],\n",
       " ['으로', '간추린', '다음', '수정'],\n",
       " ['간추린', '다음', '수정', '을'],\n",
       " ['다음', '수정', '을', '했'],\n",
       " ['수정', '을', '했', '고'],\n",
       " ['을', '했', '고', '브라이트'],\n",
       " ['했', '고', '브라이트', '코프'],\n",
       " ['고', '브라이트', '코프', '흐'],\n",
       " ['브라이트', '코프', '흐', '&'],\n",
       " ['코프', '흐', '&', '헤르'],\n",
       " ['흐', '&', '헤르', '텔'],\n",
       " ['&', '헤르', '텔', '출판사'],\n",
       " ['헤르', '텔', '출판사', '에서'],\n",
       " ['텔', '출판사', '에서', '출판'],\n",
       " ['출판사', '에서', '출판', '할'],\n",
       " ['에서', '출판', '할', '개정판'],\n",
       " ['출판', '할', '개정판', '도'],\n",
       " ['할', '개정판', '도', '준비'],\n",
       " ['개정판', '도', '준비', '했'],\n",
       " ['도', '준비', '했', '다'],\n",
       " ['준비', '했', '다', '.'],\n",
       " ['했', '다', '.', '1'],\n",
       " ['다', '.', '1', '8'],\n",
       " ['.', '1', '8', '5'],\n",
       " ['1', '8', '5', '3'],\n",
       " ['8', '5', '3', '년'],\n",
       " ['5', '3', '년', '5'],\n",
       " ['3', '년', '5', '월'],\n",
       " ['년', '5', '월', '에'],\n",
       " ['5', '월', '에', '는'],\n",
       " ['월', '에', '는', '리스트'],\n",
       " ['에', '는', '리스트', '가'],\n",
       " ['는', '리스트', '가', '이'],\n",
       " ['리스트', '가', '이', '작품'],\n",
       " ['가', '이', '작품', '이'],\n",
       " ['이', '작품', '이', '수정'],\n",
       " ['작품', '이', '수정', '되'],\n",
       " ['이', '수정', '되', '었'],\n",
       " ['수정', '되', '었', '다는'],\n",
       " ['되', '었', '다는', '것'],\n",
       " ['었', '다는', '것', '을'],\n",
       " ['다는', '것', '을', '인정'],\n",
       " ['것', '을', '인정', '했'],\n",
       " ['을', '인정', '했', '지만'],\n",
       " ['인정', '했', '지만', ','],\n",
       " ['했', '지만', ',', '끝내'],\n",
       " ['지만', ',', '끝내', '바그너'],\n",
       " [',', '끝내', '바그너', '의'],\n",
       " ['끝내', '바그너', '의', '출판'],\n",
       " ['바그너', '의', '출판', '계획'],\n",
       " ['의', '출판', '계획', '은'],\n",
       " ['출판', '계획', '은', '무산'],\n",
       " ['계획', '은', '무산', '되'],\n",
       " ['은', '무산', '되', '고'],\n",
       " ['무산', '되', '고', '말'],\n",
       " ['되', '고', '말', '았'],\n",
       " ['고', '말', '았', '다'],\n",
       " ['말', '았', '다', '.'],\n",
       " ['았', '다', '.', '이후'],\n",
       " ['다', '.', '이후', '1'],\n",
       " ['.', '이후', '1', '8'],\n",
       " ['이후', '1', '8', '5'],\n",
       " ['1', '8', '5', '5'],\n",
       " ['8', '5', '5', '년'],\n",
       " ['5', '5', '년', '에'],\n",
       " ['5', '년', '에', '리스트'],\n",
       " ['년', '에', '리스트', '가'],\n",
       " ['에', '리스트', '가', '자신'],\n",
       " ['리스트', '가', '자신', '의'],\n",
       " ['가', '자신', '의', '작품'],\n",
       " ['자신', '의', '작품', '파우스트'],\n",
       " ['의', '작품', '파우스트', '교향곡'],\n",
       " ['작품', '파우스트', '교향곡', '을'],\n",
       " ['파우스트', '교향곡', '을', '거의'],\n",
       " ['교향곡', '을', '거의', '완성'],\n",
       " ['을', '거의', '완성', '하'],\n",
       " ['거의', '완성', '하', '여'],\n",
       " ['완성', '하', '여', '그'],\n",
       " ['하', '여', '그', '사실'],\n",
       " ['여', '그', '사실', '을'],\n",
       " ['그', '사실', '을', '바그너'],\n",
       " ['사실', '을', '바그너', '에게'],\n",
       " ['을', '바그너', '에게', '알렸'],\n",
       " ['바그너', '에게', '알렸', '고'],\n",
       " ['에게', '알렸', '고', ','],\n",
       " ['알렸', '고', ',', '바그너'],\n",
       " ['고', ',', '바그너', '는'],\n",
       " [',', '바그너', '는', '다시'],\n",
       " ['바그너', '는', '다시', '개정'],\n",
       " ['는', '다시', '개정', '된'],\n",
       " ['다시', '개정', '된', '총보'],\n",
       " ['개정', '된', '총보', '를'],\n",
       " ['된', '총보', '를', '리스트'],\n",
       " ['총보', '를', '리스트', '에게'],\n",
       " ['를', '리스트', '에게', '보내'],\n",
       " ['리스트', '에게', '보내', '고'],\n",
       " ['에게', '보내', '고', '브라이트'],\n",
       " ['보내', '고', '브라이트', '코프'],\n",
       " ['고', '브라이트', '코프', '흐'],\n",
       " ['브라이트', '코프', '흐', '&'],\n",
       " ['코프', '흐', '&', '헤르'],\n",
       " ['흐', '&', '헤르', '텔'],\n",
       " ['&', '헤르', '텔', '출판사'],\n",
       " ['헤르', '텔', '출판사', '에'],\n",
       " ['텔', '출판사', '에', '는'],\n",
       " ['출판사', '에', '는', '2'],\n",
       " ['에', '는', '2', '0'],\n",
       " ['는', '2', '0', '루이'],\n",
       " ['2', '0', '루이', '의'],\n",
       " ['0', '루이', '의', '금'],\n",
       " ['루이', '의', '금', '을'],\n",
       " ['의', '금', '을', '받'],\n",
       " ['금', '을', '받', '고'],\n",
       " ['을', '받', '고', '팔'],\n",
       " ['받', '고', '팔', '았'],\n",
       " ['고', '팔', '았', '다'],\n",
       " ['팔', '았', '다', '.'],\n",
       " ['았', '다', '.', '또한'],\n",
       " ['다', '.', '또한', '그'],\n",
       " ['.', '또한', '그', '의'],\n",
       " ['또한', '그', '의', '작품'],\n",
       " ['그', '의', '작품', '을'],\n",
       " ['의', '작품', '을', '“'],\n",
       " ['작품', '을', '“', '하나하나'],\n",
       " ['을', '“', '하나하나', '의'],\n",
       " ['“', '하나하나', '의', '음표'],\n",
       " ['하나하나', '의', '음표', '가'],\n",
       " ['의', '음표', '가', '시인'],\n",
       " ['음표', '가', '시인', '의'],\n",
       " ['가', '시인', '의', '피'],\n",
       " ['시인', '의', '피', '로'],\n",
       " ['의', '피', '로', '쓰여졌'],\n",
       " ['피', '로', '쓰여졌', '다'],\n",
       " ['로', '쓰여졌', '다', '”'],\n",
       " ['쓰여졌', '다', '”', '며'],\n",
       " ['다', '”', '며', '극찬'],\n",
       " ['”', '며', '극찬', '했'],\n",
       " ['며', '극찬', '했', '던'],\n",
       " ['극찬', '했', '던', '한스'],\n",
       " ['했', '던', '한스', '폰'],\n",
       " ['던', '한스', '폰', '뷜로'],\n",
       " ['한스', '폰', '뷜로', '가'],\n",
       " ['폰', '뷜로', '가', '그것'],\n",
       " ['뷜로', '가', '그것', '을'],\n",
       " ['가', '그것', '을', '피아노'],\n",
       " ['그것', '을', '피아노', '독주'],\n",
       " ['을', '피아노', '독주', '용'],\n",
       " ['피아노', '독주', '용', '으로'],\n",
       " ['독주', '용', '으로', '편곡'],\n",
       " ['용', '으로', '편곡', '했'],\n",
       " ['으로', '편곡', '했', '는데'],\n",
       " ['편곡', '했', '는데', ','],\n",
       " ['했', '는데', ',', '리스트'],\n",
       " ['는데', ',', '리스트', '는'],\n",
       " [',', '리스트', '는', '그것'],\n",
       " ['리스트', '는', '그것', '을'],\n",
       " ['는', '그것', '을', '약간'],\n",
       " ['그것', '을', '약간', '변형'],\n",
       " ['을', '약간', '변형', '되'],\n",
       " ['약간', '변형', '되', '었'],\n",
       " ['변형', '되', '었', '을'],\n",
       " ['되', '었', '을', '뿐'],\n",
       " ['었', '을', '뿐', '이'],\n",
       " ['을', '뿐', '이', '라고'],\n",
       " ['뿐', '이', '라고', '지적'],\n",
       " ['이', '라고', '지적', '했'],\n",
       " ['라고', '지적', '했', '다'],\n",
       " ['지적', '했', '다', '.'],\n",
       " ['했', '다', '.', '이'],\n",
       " ['다', '.', '이', '서곡'],\n",
       " ['.', '이', '서곡', '의'],\n",
       " ['이', '서곡', '의', '총보'],\n",
       " ['서곡', '의', '총보', '첫머리'],\n",
       " ['의', '총보', '첫머리', '에'],\n",
       " ['총보', '첫머리', '에', '는'],\n",
       " ['첫머리', '에', '는', '파우스트'],\n",
       " ['에', '는', '파우스트', '1'],\n",
       " ['는', '파우스트', '1', '부'],\n",
       " ['파우스트', '1', '부', '의'],\n",
       " ['1', '부', '의', '내용'],\n",
       " ['부', '의', '내용', '중'],\n",
       " ['의', '내용', '중', '한'],\n",
       " ['내용', '중', '한', '구절'],\n",
       " ['중', '한', '구절', '을'],\n",
       " ['한', '구절', '을', '인용'],\n",
       " ['구절', '을', '인용', '하'],\n",
       " ['을', '인용', '하', '고'],\n",
       " ['인용', '하', '고', '있'],\n",
       " ['하', '고', '있', '다'],\n",
       " ['고', '있', '다', '.'],\n",
       " ['바그너', '의', '작품', '을'],\n",
       " ['의', '작품', '을', '시인'],\n",
       " ['작품', '을', '시인', '의'],\n",
       " ['을', '시인', '의', '피'],\n",
       " ['시인', '의', '피', '로'],\n",
       " ['의', '피', '로', '쓰여졌'],\n",
       " ['피', '로', '쓰여졌', '다고'],\n",
       " ['로', '쓰여졌', '다고', '극찬'],\n",
       " ['쓰여졌', '다고', '극찬', '한'],\n",
       " ['다고', '극찬', '한', '것'],\n",
       " ['극찬', '한', '것', '은'],\n",
       " ['한', '것', '은', '누구'],\n",
       " ['것', '은', '누구', '인가'],\n",
       " ['은', '누구', '인가', '?'],\n",
       " ['누구', '인가', '?', '한스'],\n",
       " ['인가', '?', '한스', '폰'],\n",
       " ['?', '한스', '폰', '뷜로'],\n",
       " ['잊혀져', '있', '는', '파우스트'],\n",
       " ['있', '는', '파우스트', '서곡'],\n",
       " ['는', '파우스트', '서곡', '1'],\n",
       " ['파우스트', '서곡', '1', '악장'],\n",
       " ['서곡', '1', '악장', '을'],\n",
       " ['1', '악장', '을', '부활'],\n",
       " ['악장', '을', '부활', '시킨'],\n",
       " ['을', '부활', '시킨', '것'],\n",
       " ['부활', '시킨', '것', '은'],\n",
       " ['시킨', '것', '은', '누구'],\n",
       " ['것', '은', '누구', '인가'],\n",
       " ['은', '누구', '인가', '?'],\n",
       " ['누구', '인가', '?', '리스트'],\n",
       " ['바그너', '는', '다시', '개정'],\n",
       " ['는', '다시', '개정', '된'],\n",
       " ['다시', '개정', '된', '총보'],\n",
       " ['개정', '된', '총보', '를'],\n",
       " ['된', '총보', '를', '얼마'],\n",
       " ['총보', '를', '얼마', '를'],\n",
       " ['를', '얼마', '를', '받'],\n",
       " ['얼마', '를', '받', '고'],\n",
       " ['를', '받', '고', '팔'],\n",
       " ['받', '고', '팔', '았'],\n",
       " ['고', '팔', '았', '는가'],\n",
       " ['팔', '았', '는가', '?'],\n",
       " ['았', '는가', '?', '2'],\n",
       " ['는가', '?', '2', '0'],\n",
       " ['?', '2', '0', '루이'],\n",
       " ['2', '0', '루이', '의'],\n",
       " ['0', '루이', '의', '금'],\n",
       " ['파우스트', '교향곡', '을', '부활'],\n",
       " ['교향곡', '을', '부활', '시킨'],\n",
       " ['을', '부활', '시킨', '사람'],\n",
       " ['부활', '시킨', '사람', '은'],\n",
       " ['시킨', '사람', '은', '?'],\n",
       " ['사람', '은', '?', '리스트'],\n",
       " ['파우스트', '교향곡', '을', '피아노'],\n",
       " ['교향곡', '을', '피아노', '독주'],\n",
       " ['을', '피아노', '독주', '용'],\n",
       " ['피아노', '독주', '용', '으로'],\n",
       " ['독주', '용', '으로', '편곡'],\n",
       " ['용', '으로', '편곡', '한'],\n",
       " ['으로', '편곡', '한', '사람'],\n",
       " ['편곡', '한', '사람', '은'],\n",
       " ['한', '사람', '은', '?'],\n",
       " ['사람', '은', '?', '한스'],\n",
       " ['은', '?', '한스', '폰'],\n",
       " ['?', '한스', '폰', '뷜로'],\n",
       " ['1', '악장', '을', '부활'],\n",
       " ['악장', '을', '부활', '시켜'],\n",
       " ['을', '부활', '시켜', '연주'],\n",
       " ['부활', '시켜', '연주', '한'],\n",
       " ['시켜', '연주', '한', '사람'],\n",
       " ['연주', '한', '사람', '은'],\n",
       " ['한', '사람', '은', '?'],\n",
       " ['사람', '은', '?', '리스트'],\n",
       " ['파우스트', '교향곡', '에', '감탄'],\n",
       " ['교향곡', '에', '감탄', '하'],\n",
       " ['에', '감탄', '하', '여'],\n",
       " ['감탄', '하', '여', '피아노'],\n",
       " ['하', '여', '피아노', '곡'],\n",
       " ['여', '피아노', '곡', '으로'],\n",
       " ['피아노', '곡', '으로', '편곡'],\n",
       " ['곡', '으로', '편곡', '한'],\n",
       " ['으로', '편곡', '한', '사람'],\n",
       " ['편곡', '한', '사람', '은'],\n",
       " ['한', '사람', '은', '?'],\n",
       " ['사람', '은', '?', '한스'],\n",
       " ['은', '?', '한스', '폰'],\n",
       " ['?', '한스', '폰', '뷜로'],\n",
       " ['리스트', '가', '바그너', '와'],\n",
       " ['가', '바그너', '와', '알'],\n",
       " ['바그너', '와', '알', '게'],\n",
       " ['와', '알', '게', '된'],\n",
       " ['알', '게', '된', '연도'],\n",
       " ['게', '된', '연도', '는'],\n",
       " ['된', '연도', '는', '?'],\n",
       " ['연도', '는', '?', '1'],\n",
       " ['는', '?', '1', '8'],\n",
       " ['?', '1', '8', '4'],\n",
       " ['1', '8', '4', '0'],\n",
       " ['8', '4', '0', '년'],\n",
       " ['이', '작품', '은', '라단조'],\n",
       " ['작품', '은', '라단조', ','],\n",
       " ['은', '라단조', ',', 'Sehr'],\n",
       " ['라단조', ',', 'Sehr', 'gehalten'],\n",
       " [',', 'Sehr', 'gehalten', '('],\n",
       " ['Sehr', 'gehalten', '(', '아주'],\n",
       " ['gehalten', '(', '아주', '신중'],\n",
       " ['(', '아주', '신중', '하'],\n",
       " ['아주', '신중', '하', '게'],\n",
       " ['신중', '하', '게', ')'],\n",
       " ['하', '게', ')', ','],\n",
       " ['게', ')', ',', '4'],\n",
       " [')', ',', '4', '/'],\n",
       " [',', '4', '/', '4'],\n",
       " ['4', '/', '4', '박자'],\n",
       " ['/', '4', '박자', '의'],\n",
       " ['4', '박자', '의', '부드러운'],\n",
       " ['박자', '의', '부드러운', '서주'],\n",
       " ['의', '부드러운', '서주', '로'],\n",
       " ['부드러운', '서주', '로', '서주'],\n",
       " ['서주', '로', '서주', '로'],\n",
       " ['로', '서주', '로', '시작'],\n",
       " ['서주', '로', '시작', '되'],\n",
       " ['로', '시작', '되', '는데'],\n",
       " ['시작', '되', '는데', ','],\n",
       " ['되', '는데', ',', '여기'],\n",
       " ['는데', ',', '여기', '에'],\n",
       " [',', '여기', '에', '는'],\n",
       " ['여기', '에', '는', '주요'],\n",
       " ['에', '는', '주요', '주제'],\n",
       " ['는', '주요', '주제', ','],\n",
       " ['주요', '주제', ',', '동기'],\n",
       " ['주제', ',', '동기', '의'],\n",
       " [',', '동기', '의', '대부분'],\n",
       " ['동기', '의', '대부분', '이'],\n",
       " ['의', '대부분', '이', '암시'],\n",
       " ['대부분', '이', '암시', ','],\n",
       " ['이', '암시', ',', '예고'],\n",
       " ['암시', ',', '예고', '되'],\n",
       " [',', '예고', '되', '어'],\n",
       " ['예고', '되', '어', '있'],\n",
       " ['되', '어', '있', '다'],\n",
       " ['어', '있', '다', '.'],\n",
       " ['있', '다', '.', '첫'],\n",
       " ['다', '.', '첫', '부분'],\n",
       " ['.', '첫', '부분', '의'],\n",
       " ['첫', '부분', '의', '저음'],\n",
       " ['부분', '의', '저음', '주제'],\n",
       " ['의', '저음', '주제', '는'],\n",
       " ['저음', '주제', '는', '주요'],\n",
       " ['주제', '는', '주요', '주제'],\n",
       " ['는', '주요', '주제', '('],\n",
       " ['주요', '주제', '(', '고뇌'],\n",
       " ['주제', '(', '고뇌', '와'],\n",
       " ['(', '고뇌', '와', '갈망'],\n",
       " ['고뇌', '와', '갈망', '동기'],\n",
       " ['와', '갈망', '동기', ','],\n",
       " ['갈망', '동기', ',', '청춘'],\n",
       " ['동기', ',', '청춘', '의'],\n",
       " [',', '청춘', '의', '사랑'],\n",
       " ['청춘', '의', '사랑', '동기'],\n",
       " ['의', '사랑', '동기', ')'],\n",
       " ['사랑', '동기', ')', '를'],\n",
       " ['동기', ')', '를', '암시'],\n",
       " [')', '를', '암시', '하'],\n",
       " ['를', '암시', '하', '고'],\n",
       " ['암시', '하', '고', '있'],\n",
       " ['하', '고', '있', '으며'],\n",
       " ['고', '있', '으며', ','],\n",
       " ['있', '으며', ',', '제'],\n",
       " ['으며', ',', '제', '1'],\n",
       " [',', '제', '1', '바이올린'],\n",
       " ['제', '1', '바이올린', '으로'],\n",
       " ['1', '바이올린', '으로', '더욱'],\n",
       " ['바이올린', '으로', '더욱', '명확'],\n",
       " ['으로', '더욱', '명확', '하'],\n",
       " ['더욱', '명확', '하', '게'],\n",
       " ['명확', '하', '게', '나타난다'],\n",
       " ['하', '게', '나타난다', '.'],\n",
       " ['게', '나타난다', '.', '또한'],\n",
       " ['나타난다', '.', '또한', '그것'],\n",
       " ['.', '또한', '그것', '을'],\n",
       " ['또한', '그것', '을', '이어받'],\n",
       " ['그것', '을', '이어받', '는'],\n",
       " ['을', '이어받', '는', '동기'],\n",
       " ['이어받', '는', '동기', '도'],\n",
       " ['는', '동기', '도', '중요'],\n",
       " ['동기', '도', '중요', '한'],\n",
       " ['도', '중요', '한', '역할'],\n",
       " ['중요', '한', '역할', '을'],\n",
       " ['한', '역할', '을', '한다'],\n",
       " ['역할', '을', '한다', '.'],\n",
       " ['을', '한다', '.', '여기'],\n",
       " ['한다', '.', '여기', '에'],\n",
       " ['.', '여기', '에', '새로운'],\n",
       " ['여기', '에', '새로운', '소재'],\n",
       " ['에', '새로운', '소재', '가'],\n",
       " ['새로운', '소재', '가', '더'],\n",
       " ['소재', '가', '더', '해진'],\n",
       " ['가', '더', '해진', '뒤'],\n",
       " ['더', '해진', '뒤', '에'],\n",
       " ['해진', '뒤', '에', '새로운'],\n",
       " ['뒤', '에', '새로운', '주제'],\n",
       " ['에', '새로운', '주제', '도'],\n",
       " ['새로운', '주제', '도', '연주'],\n",
       " ['주제', '도', '연주', '된다'],\n",
       " ['도', '연주', '된다', '.'],\n",
       " ['연주', '된다', '.', '주요부'],\n",
       " ['된다', '.', '주요부', '는'],\n",
       " ['.', '주요부', '는', 'Sehr'],\n",
       " ['주요부', '는', 'Sehr', 'bewegt'],\n",
       " ['는', 'Sehr', 'bewegt', '('],\n",
       " ['Sehr', 'bewegt', '(', '아주'],\n",
       " ['bewegt', '(', '아주', '격동'],\n",
       " ['(', '아주', '격동', '적'],\n",
       " ['아주', '격동', '적', '으로'],\n",
       " ['격동', '적', '으로', ')'],\n",
       " ['적', '으로', ')', ','],\n",
       " ['으로', ')', ',', '2'],\n",
       " [')', ',', '2', '/'],\n",
       " [',', '2', '/', '2'],\n",
       " ['2', '/', '2', '박자'],\n",
       " ['/', '2', '박자', '의'],\n",
       " ['2', '박자', '의', '자유'],\n",
       " ['박자', '의', '자유', '로운'],\n",
       " ['의', '자유', '로운', '소나타'],\n",
       " ['자유', '로운', '소나타', '형식'],\n",
       " ['로운', '소나타', '형식', '으로'],\n",
       " ['소나타', '형식', '으로', '매우'],\n",
       " ['형식', '으로', '매우', '드라마틱'],\n",
       " ['으로', '매우', '드라마틱', '한'],\n",
       " ['매우', '드라마틱', '한', '구상'],\n",
       " ['드라마틱', '한', '구상', '과'],\n",
       " ['한', '구상', '과', '유기'],\n",
       " ['구상', '과', '유기', '적'],\n",
       " ['과', '유기', '적', '인'],\n",
       " ['유기', '적', '인', '구성'],\n",
       " ['적', '인', '구성', '을'],\n",
       " ['인', '구성', '을', '하'],\n",
       " ['구성', '을', '하', '고'],\n",
       " ['을', '하', '고', '있'],\n",
       " ['하', '고', '있', '다'],\n",
       " ['고', '있', '다', '.'],\n",
       " ['있', '다', '.', '여기'],\n",
       " ['다', '.', '여기', '에'],\n",
       " ['.', '여기', '에', '는'],\n",
       " ['여기', '에', '는', '지금'],\n",
       " ['에', '는', '지금', '까지'],\n",
       " ['는', '지금', '까지', '의'],\n",
       " ['지금', '까지', '의', '주제'],\n",
       " ['까지', '의', '주제', '나'],\n",
       " ['의', '주제', '나', '소재'],\n",
       " ['주제', '나', '소재', '외'],\n",
       " ['나', '소재', '외', '에'],\n",
       " ['소재', '외', '에', '도'],\n",
       " ['외', '에', '도', '오보에'],\n",
       " ['에', '도', '오보에', '에'],\n",
       " ['도', '오보에', '에', '의한'],\n",
       " ['오보에', '에', '의한', '선율'],\n",
       " ['에', '의한', '선율', '과'],\n",
       " ['의한', '선율', '과', '제'],\n",
       " ['선율', '과', '제', '2'],\n",
       " ['과', '제', '2', '주제'],\n",
       " ['제', '2', '주제', '를'],\n",
       " ['2', '주제', '를', '떠올리'],\n",
       " ['주제', '를', '떠올리', '게'],\n",
       " ['를', '떠올리', '게', '하'],\n",
       " ['떠올리', '게', '하', '는'],\n",
       " ['게', '하', '는', '부차'],\n",
       " ['하', '는', '부차', '적'],\n",
       " ['는', '부차', '적', '인'],\n",
       " ['부차', '적', '인', '주제'],\n",
       " ['적', '인', '주제', '가'],\n",
       " ['인', '주제', '가', '더'],\n",
       " ['주제', '가', '더', '해'],\n",
       " ['가', '더', '해', '지'],\n",
       " ['더', '해', '지', '는데'],\n",
       " ['해', '지', '는데', ','],\n",
       " ['지', '는데', ',', '중간부'],\n",
       " ['는데', ',', '중간부', '에서'],\n",
       " [',', '중간부', '에서', '는'],\n",
       " ['중간부', '에서', '는', '약보'],\n",
       " ['에서', '는', '약보', '3'],\n",
       " ['는', '약보', '3', '이'],\n",
       " ['약보', '3', '이', '중심'],\n",
       " ['3', '이', '중심', '이'],\n",
       " ['이', '중심', '이', '되'],\n",
       " ['중심', '이', '되', '고'],\n",
       " ['이', '되', '고', '제'],\n",
       " ['되', '고', '제', '2'],\n",
       " ['고', '제', '2', '주제'],\n",
       " ['제', '2', '주제', '는'],\n",
       " ['2', '주제', '는', '축소'],\n",
       " ['주제', '는', '축소', '된'],\n",
       " ['는', '축소', '된', '재현부'],\n",
       " ['축소', '된', '재현부', '에서'],\n",
       " ['된', '재현부', '에서', 'D'],\n",
       " ['재현부', '에서', 'D', '장조'],\n",
       " ['에서', 'D', '장조', '로'],\n",
       " ['D', '장조', '로', '재현'],\n",
       " ['장조', '로', '재현', '된다'],\n",
       " ['로', '재현', '된다', '.'],\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3862986"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_vec(sent):\n",
    "    vec = []\n",
    "    for word in sent:\n",
    "        vec.append(word_to_id[word])\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_target = []\n",
    "for data in train_data:\n",
    "    train_input.append(sent_to_vec(data[:-1]))\n",
    "    train_target.append(word_to_id[data[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3862986, 3862986)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input), len(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([50472, 65316, 52881], 9126)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0], train_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_input_ts = torch.tensor(train_input)\n",
    "train_target_ts = torch.tensor(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(train_input_ts, train_target_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델을 만들어보자.\n",
    "\n",
    "먼저 임베딩 벡터를 concatenate하는 방법에 대해 고민해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(len(vocab) * (N-1), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = emb(torch.tensor([train_input[0]]))\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9689,  0.5371,  2.0395,  1.3356, -0.6704,  0.0093, -1.1420,  1.7707,\n",
       "         1.9236,  0.6581,  1.2249, -0.0710,  0.6953, -0.9278, -0.0994],\n",
       "       grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 입력을 하나씩 받을 경우는 그냥 flatten 쓰면 되지만, 배치로 받을 때는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = emb(torch.tensor([train_input[0],train_input[1]]))\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9689,  0.5371,  2.0395,  1.3356, -0.6704],\n",
       "         [ 0.0093, -1.1420,  1.7707,  1.9236,  0.6581],\n",
       "         [ 1.2249, -0.0710,  0.6953, -0.9278, -0.0994]],\n",
       "\n",
       "        [[ 0.0093, -1.1420,  1.7707,  1.9236,  0.6581],\n",
       "         [ 1.2249, -0.0710,  0.6953, -0.9278, -0.0994],\n",
       "         [-3.7253,  0.1673,  0.1281,  0.9819, -0.5825]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9689,  0.5371,  2.0395,  1.3356, -0.6704,  0.0093, -1.1420,  1.7707,\n",
       "          1.9236,  0.6581],\n",
       "        [ 0.0093, -1.1420,  1.7707,  1.9236,  0.6581,  1.2249, -0.0710,  0.6953,\n",
       "         -0.9278, -0.0994],\n",
       "        [ 1.2249, -0.0710,  0.6953, -0.9278, -0.0994, -3.7253,  0.1673,  0.1281,\n",
       "          0.9819, -0.5825]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_tu= torch.cat(tuple(vec),1)\n",
    "vec_tu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cat은 안될 것 같고, 찾아보니 flatten에 start_dim 옵션이 있음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.flatten??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9689,  0.5371,  2.0395,  1.3356, -0.6704,  0.0093, -1.1420,  1.7707,\n",
       "          1.9236,  0.6581,  1.2249, -0.0710,  0.6953, -0.9278, -0.0994],\n",
       "        [ 0.0093, -1.1420,  1.7707,  1.9236,  0.6581,  1.2249, -0.0710,  0.6953,\n",
       "         -0.9278, -0.0994, -3.7253,  0.1673,  0.1281,  0.9819, -0.5825]],\n",
       "       grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_tu= torch.flatten(vec,1)\n",
    "vec_tu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원하는 결과를 얻음!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "근데 어차피 Linear layer가 필요하므로 원핫인코딩을 해야함..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.tensor([train_input[0],train_input[1]])\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인덱스 벡터를 받으면 원핫인코딩 벡터를 반환하는 함수를 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_onehot(vec, oh_len):\n",
    "    ohv = torch.zeros((batch.shape[0], batch.shape[1], oh_len))\n",
    "    for i in range(vec.shape[0]):\n",
    "        for j in range(vec.shape[1]):\n",
    "            ohv[i][j][vec[i][j]] = 1\n",
    "            \n",
    "    return ohv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 83593])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_to_onehot(batch, len(vocab)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_oh = vec_to_onehot(batch, len(vocab))\n",
    "vec_oh_tu= torch.flatten(vec_oh,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 250779])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_oh_tu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(len(vocab) * (N-1), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(vec_oh_tu).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아예 이 과정을 하나의 함수로 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_input(batch, oh_len):\n",
    "    ohv = torch.zeros((batch.shape[0], batch.shape[1], oh_len))\n",
    "    for i in range(batch.shape[0]):\n",
    "        for j in range(batch.shape[1]):\n",
    "            ohv[i][j][batch[i][j]] = 1\n",
    "            \n",
    "    return torch.flatten(ohv,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 250779])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_to_input(batch, len(vocab)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(batch_to_input(batch, len(vocab))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각해보니 착각을 했다. 모델의 입력은 인덱스로 받아서 먼저 벡터 임베딩 후 Linear layer에 태우면 되니까, 그냥 임베딩 써도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPLM(nn.Module):\n",
    "    def __init__(self, n, vec_dim, hidden_dim):\n",
    "        super(NPLM,self).__init__()\n",
    "        self.emb = nn.Embedding(len(vocab), vec_dim)\n",
    "        self.lin1 = nn.Linear(vec_dim * (n-1), hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, len(vocab), bias=False)\n",
    "        self.lin3 = nn.Linear(vec_dim * (n-1), len(vocab))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x : [BATCH_SIZE, N-1]\n",
    "        # self.emb(x) : [BATCH_SIZE, N-1, VEC_DIM]\n",
    "        x = self.emb(x).view(len(x),-1)\n",
    "        y = torch.tanh(self.lin1(x))\n",
    "        z = self.lin3(x) + self.lin2(y)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NPLM(N, VEC_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9126, 52737])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch = torch.tensor([train_target[0],train_target[1]])\n",
    "target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.2042, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_f(output, target_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 loss가 올바른 결과인지 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4428e-05, 1.2722e-05, 2.4266e-05,  ..., 7.4909e-06, 8.3130e-06,\n",
       "         2.4767e-06],\n",
       "        [1.2748e-05, 1.0737e-05, 1.9825e-05,  ..., 8.3171e-06, 2.4149e-05,\n",
       "         3.8782e-06]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output, 1) # output을 소프트맥스 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output, 1)[0].sum() # 차원이 맞게 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-11.4189, grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(F.softmax(output, 1)[0][target_batch[0]]) # 출력의 target번째 좌표의 로그값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.9895, grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(F.softmax(output, 1)[1][target_batch[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.2042, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(torch.log(F.softmax(output, 1)[0][target_batch[0]]) + torch.log(F.softmax(output, 1)[1][target_batch[1]]))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 각각의 negative loss의 평균이다! 맞게 계산됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(input_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 임베딩도 잘못 했음..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(len(vocab), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 10])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = emb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3797, -0.5497, -0.1819,  ...,  0.2293,  1.3921,  0.3705],\n",
       "         [-0.9443, -1.9360,  1.0009,  ...,  1.3524, -0.2080,  1.1619],\n",
       "         [ 1.2290, -0.0642,  0.6032,  ..., -0.1276,  0.3939,  0.1067]],\n",
       "\n",
       "        [[-0.9443, -1.9360,  1.0009,  ...,  1.3524, -0.2080,  1.1619],\n",
       "         [ 1.2290, -0.0642,  0.6032,  ..., -0.1276,  0.3939,  0.1067],\n",
       "         [ 0.6412, -0.5177,  1.2241,  ..., -0.3652, -0.4658,  1.4531]],\n",
       "\n",
       "        [[ 1.2290, -0.0642,  0.6032,  ..., -0.1276,  0.3939,  0.1067],\n",
       "         [ 0.6412, -0.5177,  1.2241,  ..., -0.3652, -0.4658,  1.4531],\n",
       "         [-0.6553, -0.0878,  0.1446,  ..., -0.9161,  1.3431,  0.0070]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.6617,  0.6439, -0.0419,  ..., -0.3900,  0.9162, -0.4438],\n",
       "         [ 0.4282, -0.8271, -0.3454,  ..., -1.4361,  0.6106, -0.6443],\n",
       "         [ 1.0708, -1.7279,  0.0475,  ...,  1.2346, -0.0447,  0.2068]],\n",
       "\n",
       "        [[ 0.4282, -0.8271, -0.3454,  ..., -1.4361,  0.6106, -0.6443],\n",
       "         [ 1.0708, -1.7279,  0.0475,  ...,  1.2346, -0.0447,  0.2068],\n",
       "         [-0.9041,  0.3556, -0.0400,  ..., -0.0195, -1.1323, -1.1402]],\n",
       "\n",
       "        [[ 1.0708, -1.7279,  0.0475,  ...,  1.2346, -0.0447,  0.2068],\n",
       "         [-0.9041,  0.3556, -0.0400,  ..., -0.0195, -1.1323, -1.1402],\n",
       "         [ 0.7355,  0.0207, -1.0938,  ...,  0.7455, -1.3573, -1.6670]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3797, -0.5497, -0.1819,  ..., -0.1276,  0.3939,  0.1067],\n",
       "        [-0.9443, -1.9360,  1.0009,  ..., -0.3652, -0.4658,  1.4531],\n",
       "        [ 1.2290, -0.0642,  0.6032,  ..., -0.9161,  1.3431,  0.0070],\n",
       "        ...,\n",
       "        [-0.6617,  0.6439, -0.0419,  ...,  1.2346, -0.0447,  0.2068],\n",
       "        [ 0.4282, -0.8271, -0.3454,  ..., -0.0195, -1.1323, -1.1402],\n",
       "        [ 1.0708, -1.7279,  0.0475,  ...,  0.7455, -1.3573, -1.6670]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.view(BATCH_SIZE,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Iteration : 0, Loss : 0.02, Elapsed time : 1\n",
      "Epoch : 0, Iteration : 50, Loss : 4.04, Elapsed time : 43\n",
      "Epoch : 0, Iteration : 100, Loss : 3.65, Elapsed time : 85\n",
      "Epoch : 0, Iteration : 150, Loss : 3.99, Elapsed time : 127\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-309-c5e025b229d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_ev\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_ev\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 916\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_ev\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1995\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_ev\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1314\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log_softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CPU time\n",
    "start = time.time()\n",
    "\n",
    "epoch = 1\n",
    "loss_list = []\n",
    "\n",
    "for epo in range(epoch):\n",
    "    loss_sum = 0\n",
    "    for i, (x, y) in enumerate(input_loader):\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(x)\n",
    "        \n",
    "        loss = loss_f(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        \n",
    "        if i % 50 == 0:        \n",
    "            loss_list.append(loss_sum/50)\n",
    "            print('Epoch : {}, Iteration : {}, Loss : {:.2f}, Elapsed time : {:.0f}s'.format(epo, i, loss_sum/50, time.time()-start))\n",
    "            loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU 에서 GPU 로 옮겨서 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NPLM(\n",
       "  (emb): Embedding(83593, 100)\n",
       "  (lin1): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (lin2): Linear(in_features=100, out_features=83593, bias=False)\n",
       "  (lin3): Linear(in_features=300, out_features=83593, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Iteration : 0, Loss : 0.04, Elapsed time : 1s\n",
      "Epoch : 0, Iteration : 50, Loss : 2.34, Elapsed time : 2s\n",
      "Epoch : 0, Iteration : 100, Loss : 2.49, Elapsed time : 4s\n",
      "Epoch : 0, Iteration : 150, Loss : 2.62, Elapsed time : 6s\n",
      "Epoch : 0, Iteration : 200, Loss : 5.17, Elapsed time : 8s\n",
      "Epoch : 0, Iteration : 250, Loss : 5.63, Elapsed time : 10s\n",
      "Epoch : 0, Iteration : 300, Loss : 5.91, Elapsed time : 12s\n",
      "Epoch : 0, Iteration : 350, Loss : 6.03, Elapsed time : 14s\n",
      "Epoch : 0, Iteration : 400, Loss : 6.05, Elapsed time : 16s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-313-8fd1a26977a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_ev\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_ev\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 916\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_ev\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1995\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_ev\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1314\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log_softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CPU time\n",
    "start = time.time()\n",
    "\n",
    "epoch = 1\n",
    "loss_list = []\n",
    "\n",
    "for epo in range(epoch):\n",
    "    loss_sum = 0\n",
    "    for i, (x, y) in enumerate(input_loader):\n",
    "\n",
    "        x,y = x.to(dev), y.to(dev)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(x)\n",
    "        \n",
    "        loss = loss_f(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        \n",
    "        if i % 50 == 0:        \n",
    "            loss_list.append(loss_sum/50)\n",
    "            print('Epoch : {}, Iteration : {}, Loss : {:.2f}, Elapsed time : {:.0f}s'.format(epo, i, loss_sum/50, time.time()-start))\n",
    "            loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대략 43/2 = 20배 정도 빨라짐... 갓 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = 5000\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Iteration : 0, Loss : 0.00, Elapsed time : 0s\n",
      "Epoch : 0, Iteration : 5000, Loss : 13.09, Elapsed time : 188s\n",
      "Epoch : 0, Iteration : 10000, Loss : 13.52, Elapsed time : 373s\n",
      "Epoch : 0, Iteration : 15000, Loss : 13.55, Elapsed time : 558s\n",
      "Epoch : 0, Iteration : 20000, Loss : 13.87, Elapsed time : 743s\n",
      "Epoch : 0, Iteration : 25000, Loss : 13.53, Elapsed time : 928s\n",
      "Epoch : 0, Iteration : 30000, Loss : 13.86, Elapsed time : 1113s\n",
      "Epoch : 0, Iteration : 35000, Loss : 13.95, Elapsed time : 1298s\n",
      "Epoch : 0, Iteration : 40000, Loss : 13.94, Elapsed time : 1482s\n",
      "Epoch : 0, Iteration : 45000, Loss : 14.09, Elapsed time : 1667s\n",
      "Epoch : 0, Iteration : 50000, Loss : 14.32, Elapsed time : 1852s\n",
      "Epoch : 0, Iteration : 55000, Loss : 14.30, Elapsed time : 2036s\n",
      "Epoch : 0, Iteration : 60000, Loss : 14.21, Elapsed time : 2220s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, -1]' is invalid for input of size 3000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-316-78b81e8c2d4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch_ev\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-295-438356b47803>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# x : [BATCH_SIZE, N-1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# self.emb(x) : [BATCH_SIZE, N-1, VEC_DIM]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[64, -1]' is invalid for input of size 3000"
     ]
    }
   ],
   "source": [
    "# CPU time\n",
    "start = time.time()\n",
    "\n",
    "epoch = 1\n",
    "loss_list = []\n",
    "\n",
    "for epo in range(epoch):\n",
    "    loss_sum = 0\n",
    "    for i, (x, y) in enumerate(input_loader):\n",
    "\n",
    "        x,y = x.to(dev), y.to(dev)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(x)\n",
    "        \n",
    "        loss = loss_f(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        \n",
    "        if i % check == 0:        \n",
    "            loss_list.append(loss_sum/check)\n",
    "            print('Epoch : {}, Iteration : {}, Loss : {:.2f}, Elapsed time : {:.0f}s'.format(epo, i, loss_sum/check, time.time()-start))\n",
    "            loss_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'NPLM_{}epoch.pt'.format(epoch)\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
