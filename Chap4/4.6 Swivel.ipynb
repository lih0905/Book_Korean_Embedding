{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swivel 모델은 PMI 행렬을 두 행렬 $U, V$의 곱으로 분해하는 단어 임베딩 기법이다.\n",
    "\n",
    "먼저 $i$라는 타깃 단어와 $j$라는 문맥 단어가 사용자가 정한 윈도우 내에서 단 한 건이라도 동시에 등장한 적이 있는 경우에 적용되는 목적함수는 다음과 같다. 여기서 $f(x_{ij})$는 단어 $i,j$의 동시 등장 빈도이다.\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac 12 f(x_{ij}) (U_i \\cdot V_j - \\text{PMI}(i,j))^2\n",
    "$$\n",
    "\n",
    "이는 $U_i \\cdot V_j$가 두 단어의 PMI 값과 일치하도록 두 벡터를 업데이트하며, 빈도가 높은 단어일 수록 두 벡터의 내적 값이 실제 PMI값과 좀 더 비슷해야 손실이 줄어들도록 설계된 것이다.\n",
    "\n",
    "다음으로 단어 $i,j$가 말뭉치의 특정 윈도우 내에서 동시에 등장한 적이 한 번도 없는 경우에 적용되는 목적함수는 다음과 같다. 여기서 $\\text{PMI}^*$는 단어 $i,j$의 동시 등장 횟수를 0 대신 1로 가정하고 계산한 PMI 값이다.\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\log[1+exp(U_i \\cdot V_j - \\text{PMI}^*(i,j))]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.2. 튜토리얼\n",
    "\n",
    "실제로 Swivel 모델을 학습시켜 보자. 먼저 루트 디렉토리에서 다음 명령어를 실행시키면 swivel 모델의 전처리를 수행한다.\n",
    "\n",
    "`models/swivel/fastprep --input zed/corpus_mecab.txt --output_dir data/word-embeddings/swivel/swivel.data`\n",
    "\n",
    "그런데 계속 libprotobuf.so.18 라이브러리가 없다고 에러가 나서 한참을 고생한 결과, 이 파일을 도커 이미지에서 찾아서 /usr/local/lib 에 복사하고, 해당 디렉토리에서 `sudo ldconfig` 를 실행시키니 해결되었다.\n",
    "\n",
    "이렇게 전처리된 데이터를 토대로 다음 명령어(루트에서 실행)를 실행시켜 훈련을 시키자.\n",
    "\n",
    "`python models/swivel/swivel.py --input_base_path data/word-embeddings/swivel/swivel.data --output_base_path data/word-embeddings/swivel --dim 100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_path = '../data/word-embeddings/swivel/row_embedding.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = [sent.replace('\\n','').split('\\t') for sent in open(vec_path, 'r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['전',\n",
       " '0.05000429',\n",
       " '-0.3234634',\n",
       " '0.1544087',\n",
       " '-0.0027086511',\n",
       " '-0.17429611',\n",
       " '-0.05456119',\n",
       " '-0.10870183',\n",
       " '-0.26186827',\n",
       " '0.022473343',\n",
       " '0.14063968',\n",
       " '0.17234242',\n",
       " '-0.057097852',\n",
       " '-0.18921879',\n",
       " '0.31091774',\n",
       " '-0.15317011',\n",
       " '0.01634062',\n",
       " '-0.13402402',\n",
       " '0.023290195',\n",
       " '-0.13947612',\n",
       " '-0.04274352',\n",
       " '0.2697743',\n",
       " '0.19303523',\n",
       " '0.04243028',\n",
       " '-0.048464566',\n",
       " '-0.34320876',\n",
       " '-0.0007149428',\n",
       " '-0.013485536',\n",
       " '0.24820629',\n",
       " '0.17361215',\n",
       " '0.05445122',\n",
       " '-0.15588865',\n",
       " '0.16075508',\n",
       " '-0.0027796626',\n",
       " '-0.51797974',\n",
       " '0.106796704',\n",
       " '-0.32126653',\n",
       " '0.0744531',\n",
       " '-0.21878499',\n",
       " '0.05185265',\n",
       " '0.1460585',\n",
       " '0.033075005',\n",
       " '-0.30041647',\n",
       " '-0.045925476',\n",
       " '-0.19572942',\n",
       " '0.22474848',\n",
       " '0.4093167',\n",
       " '-0.011900283',\n",
       " '-0.13583928',\n",
       " '-0.1897978',\n",
       " '0.074912585',\n",
       " '0.31467316',\n",
       " '-0.0048982725',\n",
       " '0.047199816',\n",
       " '-0.09892913',\n",
       " '0.16345213',\n",
       " '-0.14114681',\n",
       " '-0.33172807',\n",
       " '0.3395185',\n",
       " '0.024566181',\n",
       " '0.33758485',\n",
       " '0.06746967',\n",
       " '0.062823795',\n",
       " '-0.024417631',\n",
       " '0.044516243',\n",
       " '-0.3153357',\n",
       " '0.052731134',\n",
       " '-0.12204204',\n",
       " '-0.13180661',\n",
       " '0.045280613',\n",
       " '-0.10529758',\n",
       " '-0.11063233',\n",
       " '0.11817169',\n",
       " '0.0035190731',\n",
       " '0.07140904',\n",
       " '-0.10595534',\n",
       " '-0.044110335',\n",
       " '-0.3565127',\n",
       " '0.30025232',\n",
       " '-0.05472579',\n",
       " '-0.039286047',\n",
       " '0.07178115',\n",
       " '-0.1788883',\n",
       " '0.04923013',\n",
       " '-0.01733116',\n",
       " '-0.18800688',\n",
       " '-0.1619643',\n",
       " '-0.28090155',\n",
       " '-0.03958892',\n",
       " '-0.0437539',\n",
       " '0.10334101',\n",
       " '-0.5063644',\n",
       " '-0.17197716',\n",
       " '0.43028197',\n",
       " '0.23381332',\n",
       " '-0.19220152',\n",
       " '-0.07522246',\n",
       " '0.08705579',\n",
       " '0.24460402',\n",
       " '0.12128688',\n",
       " '-0.23591793']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_df = pd.DataFrame(vec)\n",
    "ind = mat_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023534</td>\n",
       "      <td>-0.020808</td>\n",
       "      <td>-0.519865</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>-0.132898</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.081357</td>\n",
       "      <td>-0.246531</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.071020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604138</td>\n",
       "      <td>0.135245</td>\n",
       "      <td>0.410149</td>\n",
       "      <td>-0.076282</td>\n",
       "      <td>-0.275006</td>\n",
       "      <td>-0.746146</td>\n",
       "      <td>-0.274167</td>\n",
       "      <td>-0.134310</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>-0.085209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.100711</td>\n",
       "      <td>0.051968</td>\n",
       "      <td>0.145848</td>\n",
       "      <td>0.142244</td>\n",
       "      <td>-0.020525</td>\n",
       "      <td>-0.215196</td>\n",
       "      <td>-0.106345</td>\n",
       "      <td>0.284389</td>\n",
       "      <td>-0.143234</td>\n",
       "      <td>0.080246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103105</td>\n",
       "      <td>0.156931</td>\n",
       "      <td>-0.088146</td>\n",
       "      <td>-0.101258</td>\n",
       "      <td>0.118361</td>\n",
       "      <td>-0.119853</td>\n",
       "      <td>-0.129462</td>\n",
       "      <td>0.042567</td>\n",
       "      <td>0.085142</td>\n",
       "      <td>-0.230759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.056171</td>\n",
       "      <td>0.023841</td>\n",
       "      <td>-0.645106</td>\n",
       "      <td>-0.074233</td>\n",
       "      <td>-0.294645</td>\n",
       "      <td>0.152850</td>\n",
       "      <td>0.083372</td>\n",
       "      <td>0.054219</td>\n",
       "      <td>-0.092819</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902124</td>\n",
       "      <td>0.096833</td>\n",
       "      <td>-0.032609</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>-0.214928</td>\n",
       "      <td>-0.414776</td>\n",
       "      <td>-0.128222</td>\n",
       "      <td>-0.164744</td>\n",
       "      <td>-0.066326</td>\n",
       "      <td>-0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019248</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.541703</td>\n",
       "      <td>-0.181780</td>\n",
       "      <td>-0.187299</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>-0.016163</td>\n",
       "      <td>-0.195858</td>\n",
       "      <td>-0.114942</td>\n",
       "      <td>0.071882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.691179</td>\n",
       "      <td>-0.009627</td>\n",
       "      <td>0.199744</td>\n",
       "      <td>-0.016020</td>\n",
       "      <td>-0.268927</td>\n",
       "      <td>-0.593936</td>\n",
       "      <td>-0.247405</td>\n",
       "      <td>0.117444</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>-0.131378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>의</th>\n",
       "      <td>0.071886</td>\n",
       "      <td>-0.148137</td>\n",
       "      <td>0.329350</td>\n",
       "      <td>0.103442</td>\n",
       "      <td>-0.199225</td>\n",
       "      <td>-0.056327</td>\n",
       "      <td>-0.049317</td>\n",
       "      <td>-0.251908</td>\n",
       "      <td>0.036010</td>\n",
       "      <td>-0.111983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135906</td>\n",
       "      <td>0.071584</td>\n",
       "      <td>0.138337</td>\n",
       "      <td>0.153780</td>\n",
       "      <td>-0.241900</td>\n",
       "      <td>0.121188</td>\n",
       "      <td>-0.035508</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>0.055473</td>\n",
       "      <td>0.092082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1         2         3         4         5         6         7    \\\n",
       "0                                                                         \n",
       "1  0.023534 -0.020808 -0.519865  0.007248 -0.132898  0.225429  0.081357   \n",
       ".  0.100711  0.051968  0.145848  0.142244 -0.020525 -0.215196 -0.106345   \n",
       "0 -0.056171  0.023841 -0.645106 -0.074233 -0.294645  0.152850  0.083372   \n",
       "2  0.019248  0.061343 -0.541703 -0.181780 -0.187299  0.024887 -0.016163   \n",
       "의  0.071886 -0.148137  0.329350  0.103442 -0.199225 -0.056327 -0.049317   \n",
       "\n",
       "        8         9         10   ...       91        92        93        94   \\\n",
       "0                                ...                                           \n",
       "1 -0.246531  0.010304  0.071020  ... -0.604138  0.135245  0.410149 -0.076282   \n",
       ".  0.284389 -0.143234  0.080246  ... -0.103105  0.156931 -0.088146 -0.101258   \n",
       "0  0.054219 -0.092819  0.046763  ... -0.902124  0.096833 -0.032609 -0.011836   \n",
       "2 -0.195858 -0.114942  0.071882  ... -0.691179 -0.009627  0.199744 -0.016020   \n",
       "의 -0.251908  0.036010 -0.111983  ... -0.135906  0.071584  0.138337  0.153780   \n",
       "\n",
       "        95        96        97        98        99        100  \n",
       "0                                                              \n",
       "1 -0.275006 -0.746146 -0.274167 -0.134310  0.009054 -0.085209  \n",
       ".  0.118361 -0.119853 -0.129462  0.042567  0.085142 -0.230759  \n",
       "0 -0.214928 -0.414776 -0.128222 -0.164744 -0.066326 -0.007410  \n",
       "2 -0.268927 -0.593936 -0.247405  0.117444 -0.000361 -0.131378  \n",
       "의 -0.241900  0.121188 -0.035508  0.016112  0.055473  0.092082  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_df2 = mat_df.iloc[:,1:].astype(np.float32).copy()\n",
    "mat_df2.index = ind\n",
    "mat_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = dict()\n",
    "id2word = []\n",
    "for i, word in enumerate(ind):\n",
    "    word2id[word] = i\n",
    "    id2word.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_words(mat_df, word, k=10):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    \n",
    "    word_id = word2id[word]\n",
    "    word_vec = torch.tensor(mat_df.loc[word].values).view(1,-1)\n",
    "    word_mat = torch.tensor(mat_df.values)\n",
    "#    print(word_vec.size(), word_mat.size())\n",
    "    cos_mat = cos(word_vec, word_mat)\n",
    "    sim, indices = torch.topk(cos_mat,k+1)\n",
    "    \n",
    "    \n",
    "    word_list = []\n",
    "    for i in indices:\n",
    "        if i != word_id:\n",
    "            word_list.append(id2word[i])\n",
    "\n",
    "    return pd.Series(word_list, np.array(sim[1:].detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.683715    사단법인\n",
       "0.609789    대한민국\n",
       "0.580138     연구원\n",
       "0.580093      문화\n",
       "0.558285     연합회\n",
       "0.537043      韓國\n",
       "0.528739     공보부\n",
       "0.520811      협회\n",
       "0.518322     기자상\n",
       "0.516894     운동사\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(mat_df2, '한국')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775670      부통령\n",
       "0.740117       총리\n",
       "0.737498       선거\n",
       "0.703441      행정부\n",
       "0.674643       정부\n",
       "0.668034       버락\n",
       "0.664793      박근혜\n",
       "0.652223      전두환\n",
       "0.648393    러닝메이트\n",
       "0.642513      노무현\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(mat_df2, '대통령')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778967    서울특별시\n",
       "0.752924      특별시\n",
       "0.690524      성북구\n",
       "0.666888      종로구\n",
       "0.659213      중랑구\n",
       "0.652548      동대문\n",
       "0.650444       한양\n",
       "0.649859     서대문구\n",
       "0.643828      광진구\n",
       "0.632367      강북구\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(mat_df2, '서울')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757350     하드웨어\n",
       "0.718258    소프트웨어\n",
       "0.707026      시스템\n",
       "0.698118       응용\n",
       "0.664492      컴퓨팅\n",
       "0.661310     인공지능\n",
       "0.657708     임베디드\n",
       "0.650925    인터페이스\n",
       "0.644918       기기\n",
       "0.632106      IBM\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(mat_df2, '컴퓨터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.694390     수학\n",
       "0.688052     배웠\n",
       "0.662964    가르치\n",
       "0.649391     유학\n",
       "0.642625     학문\n",
       "0.640723     법학\n",
       "0.622810    가르쳤\n",
       "0.612421     진학\n",
       "0.610653     입학\n",
       "0.601183    하버드\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(mat_df2, '공부')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미묘하네..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(mat_df, word1, word2, word3,k=10):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    \n",
    "    word_id1 = word2id[word1]\n",
    "    word_id2 = word2id[word2]\n",
    "    word_id3 = word2id[word3]\n",
    "    word_vec1 = torch.tensor(mat_df.loc[word1].values).view(1,-1)\n",
    "    word_vec2 = torch.tensor(mat_df.loc[word2].values).view(1,-1)\n",
    "    word_vec3 = torch.tensor(mat_df.loc[word3].values).view(1,-1)\n",
    "    word_mat = torch.tensor(mat_df.values)\n",
    "    \n",
    "    cos_mat = cos(word_vec1-word_vec2+word_vec3, word_mat)\n",
    "    sim, indices = torch.topk(cos_mat,k+3)\n",
    "    \n",
    "    word_list = []\n",
    "    sim_list = []\n",
    "    for i, index in enumerate(indices):\n",
    "        if index not in (word_id1, word_id2, word_id3):\n",
    "            word_list.append(id2word[index])\n",
    "            sim_list.append(sim[i].item())\n",
    "        if len(word_list)==k:break\n",
    "    return pd.Series(word_list, sim_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.602344     프랑스\n",
       "0.474946    프랑수아\n",
       "0.462969    프랑스와\n",
       "0.458704      자크\n",
       "0.452918      샤를\n",
       "0.442147      세계\n",
       "0.440298     로베르\n",
       "0.440120    프로방스\n",
       "0.439906      유럽\n",
       "0.439256    이탈리아\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(mat_df2,'한국','서울','파리')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.488349     공주\n",
       "0.458629    제후국\n",
       "0.447652     혜왕\n",
       "0.439109     멸하\n",
       "0.436186     왕국\n",
       "0.436132     섭정\n",
       "0.434450     책봉\n",
       "0.431170     哀王\n",
       "0.421578     대왕\n",
       "0.419642     왕전\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(mat_df2,'왕','남자','여자')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analogy 테스트는 그럭저럭 괜찮은 것 같기도?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
