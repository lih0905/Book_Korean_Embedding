{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Word2Vec\n",
    "\n",
    "먼저 책 내용을 따라한 후 파이토치로 구현해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_fname = '../data/tokenized/korquad_mecab.txt'\n",
    "model_fname = '../data/word_embeddings/word2vec/word2vec'\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = [sent.strip().split(\" \") for sent in open(corpus_fname, 'r', encoding='utf-8').readlines()]\n",
    "model = Word2Vec(corpus, size=100, workers=4, sg=1)\n",
    "model.save(model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Word2VecKeyedVectors' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e856058743b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'한글'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Word2VecKeyedVectors' object is not callable"
     ]
    }
   ],
   "source": [
    "model.wv('한글')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('F:\\Google 드라이브\\Programming\\한국어 임베딩')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'khaiii'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-d16ae914f038>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_eval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordEmbeddingEvaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m model = WordEmbeddingEvaluator('../data/word_embeddings/word2vec/word2vec',\\\n\u001b[0;32m      3\u001b[0m                               dim=100, tokenizer_name='mecab')\n",
      "\u001b[1;32mF:\\Google 드라이브\\Programming\\한국어 임베딩\\models\\word_eval.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msoynlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhangle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcharacter_is_korean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjamo_sentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Google 드라이브\\Programming\\한국어 임베딩\\preprocess\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msupervised_nlputils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0munsupervised_nlputils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjamo_sentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Google 드라이브\\Programming\\한국어 임베딩\\preprocess\\supervised_nlputils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkhaiii\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKhaiiiApi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOkt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKomoran\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMecab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHannanum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKkma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'khaiii'"
     ]
    }
   ],
   "source": [
    "from models.word_eval import WordEmbeddingEvaluator\n",
    "model = WordEmbeddingEvaluator('../data/word_embeddings/word2vec/word2vec',\\\n",
    "                              dim=100, tokenizer_name='mecab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4c113a03f1d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_eval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordEmbeddingEvaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m model = WordEmbeddingEvaluator('../data/word_embeddings/word2vec/word2vec',\\\n\u001b[0;32m      3\u001b[0m                               dim=100, tokenizer_name='mecab')\n",
      "\u001b[1;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에라이 망...\n",
    "\n",
    "구현이나 해보자.\n",
    "먼저 텍스트 데이터 생성부터 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3 # 윈도우 갯수\n",
    "VEC_DIM = 100 # 임베딩 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = '../data/tokenized/korquad_mecab.txt'\n",
    "corpus = [sent.strip().split() for sent in open(txt_path, 'r', encoding='utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path2 = '../data/tokenized/ratings_mecab.txt'\n",
    "corpus2 = [sent.strip().split() for sent in open(txt_path2, 'r', encoding='utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_data = corpus# + corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '8',\n",
       " '3',\n",
       " '9',\n",
       " '년',\n",
       " '바그너',\n",
       " '는',\n",
       " '괴테',\n",
       " '의',\n",
       " '파우스트',\n",
       " '을',\n",
       " '처음',\n",
       " '읽',\n",
       " '고',\n",
       " '그',\n",
       " '내용',\n",
       " '에',\n",
       " '마음',\n",
       " '이',\n",
       " '끌려',\n",
       " '이',\n",
       " '를',\n",
       " '소재',\n",
       " '로',\n",
       " '해서',\n",
       " '하나',\n",
       " '의',\n",
       " '교향곡',\n",
       " '을',\n",
       " '쓰',\n",
       " '려는',\n",
       " '뜻',\n",
       " '을',\n",
       " '갖',\n",
       " '는다',\n",
       " '.',\n",
       " '이',\n",
       " '시기',\n",
       " '바그너',\n",
       " '는',\n",
       " '1',\n",
       " '8',\n",
       " '3',\n",
       " '8',\n",
       " '년',\n",
       " '에',\n",
       " '빛',\n",
       " '독촉',\n",
       " '으로',\n",
       " '산전수전',\n",
       " '을',\n",
       " '다',\n",
       " '걲은',\n",
       " '상황',\n",
       " '이',\n",
       " '라',\n",
       " '좌절',\n",
       " '과',\n",
       " '실망',\n",
       " '에',\n",
       " '가득',\n",
       " '했으며',\n",
       " '메피스토펠레스',\n",
       " '를',\n",
       " '만나',\n",
       " '는',\n",
       " '파우스트',\n",
       " '의',\n",
       " '심경',\n",
       " '에',\n",
       " '공감',\n",
       " '했',\n",
       " '다고',\n",
       " '한다',\n",
       " '.',\n",
       " '또한',\n",
       " '파리',\n",
       " '에서',\n",
       " '아',\n",
       " '브네',\n",
       " '크',\n",
       " '의',\n",
       " '지휘',\n",
       " '로',\n",
       " '파리',\n",
       " '음악원',\n",
       " '관현악단',\n",
       " '이',\n",
       " '연주',\n",
       " '하',\n",
       " '는',\n",
       " '베토벤',\n",
       " '의',\n",
       " '교향곡',\n",
       " '9',\n",
       " '번',\n",
       " '을',\n",
       " '듣',\n",
       " '고',\n",
       " '깊',\n",
       " '은',\n",
       " '감명',\n",
       " '을',\n",
       " '받',\n",
       " '았',\n",
       " '는데',\n",
       " ',',\n",
       " '이것',\n",
       " '이',\n",
       " '이듬해',\n",
       " '1',\n",
       " '월',\n",
       " '에',\n",
       " '파우스트',\n",
       " '의',\n",
       " '서곡',\n",
       " '으로',\n",
       " '쓰여진',\n",
       " '이',\n",
       " '작품',\n",
       " '에',\n",
       " '조금',\n",
       " '이',\n",
       " '라도',\n",
       " '영향',\n",
       " '을',\n",
       " '끼쳤',\n",
       " '으리라는',\n",
       " '것',\n",
       " '은',\n",
       " '의심',\n",
       " '할',\n",
       " '여지',\n",
       " '가',\n",
       " '없',\n",
       " '다',\n",
       " '.',\n",
       " '여기',\n",
       " '의',\n",
       " '라단조',\n",
       " '조성',\n",
       " '의',\n",
       " '경우',\n",
       " '에',\n",
       " '도',\n",
       " '그',\n",
       " '의',\n",
       " '전기',\n",
       " '에',\n",
       " '적혀',\n",
       " '있',\n",
       " '는',\n",
       " '것',\n",
       " '처럼',\n",
       " '단순',\n",
       " '한',\n",
       " '정신',\n",
       " '적',\n",
       " '피로',\n",
       " '나',\n",
       " '실의',\n",
       " '가',\n",
       " '반영',\n",
       " '된',\n",
       " '것',\n",
       " '이',\n",
       " '아니',\n",
       " '라',\n",
       " '베토벤',\n",
       " '의',\n",
       " '합창',\n",
       " '교향곡',\n",
       " '조성',\n",
       " '의',\n",
       " '영향',\n",
       " '을',\n",
       " '받',\n",
       " '은',\n",
       " '것',\n",
       " '을',\n",
       " '볼',\n",
       " '수',\n",
       " '있',\n",
       " '다',\n",
       " '.',\n",
       " '그렇게',\n",
       " '교향곡',\n",
       " '작곡',\n",
       " '을',\n",
       " '1',\n",
       " '8',\n",
       " '3',\n",
       " '9',\n",
       " '년',\n",
       " '부터',\n",
       " '4',\n",
       " '0',\n",
       " '년',\n",
       " '에',\n",
       " '걸쳐',\n",
       " '파리',\n",
       " '에서',\n",
       " '착수',\n",
       " '했으나',\n",
       " '1',\n",
       " '악장',\n",
       " '을',\n",
       " '쓴',\n",
       " '뒤',\n",
       " '에',\n",
       " '중단',\n",
       " '했',\n",
       " '다',\n",
       " '.',\n",
       " '또한',\n",
       " '작품',\n",
       " '의',\n",
       " '완성',\n",
       " '과',\n",
       " '동시',\n",
       " '에',\n",
       " '그',\n",
       " '는',\n",
       " '이',\n",
       " '서곡',\n",
       " '(',\n",
       " '1',\n",
       " '악장',\n",
       " ')',\n",
       " '을',\n",
       " '파리',\n",
       " '음악원',\n",
       " '의',\n",
       " '연주회',\n",
       " '에서',\n",
       " '연주',\n",
       " '할',\n",
       " '파트',\n",
       " '보',\n",
       " '까지',\n",
       " '준비',\n",
       " '하',\n",
       " '였으나',\n",
       " ',',\n",
       " '실제로',\n",
       " '는',\n",
       " '이루',\n",
       " '어',\n",
       " '지지',\n",
       " '는',\n",
       " '않',\n",
       " '았',\n",
       " '다',\n",
       " '.',\n",
       " '결국',\n",
       " '초연',\n",
       " '은',\n",
       " '4',\n",
       " '년',\n",
       " '반',\n",
       " '이',\n",
       " '지난',\n",
       " '후',\n",
       " '에',\n",
       " '드레스덴',\n",
       " '에서',\n",
       " '연주',\n",
       " '되',\n",
       " '었',\n",
       " '고',\n",
       " '재연',\n",
       " '도',\n",
       " '이루',\n",
       " '어',\n",
       " '졌',\n",
       " '지만',\n",
       " ',',\n",
       " '이후',\n",
       " '에',\n",
       " '그대로',\n",
       " '방치',\n",
       " '되',\n",
       " '고',\n",
       " '말',\n",
       " '았',\n",
       " '다',\n",
       " '.',\n",
       " '그',\n",
       " '사이',\n",
       " '에',\n",
       " '그',\n",
       " '는',\n",
       " '리엔치',\n",
       " '와',\n",
       " '방황',\n",
       " '하',\n",
       " '는',\n",
       " '네덜란드인',\n",
       " '을',\n",
       " '완성',\n",
       " '하',\n",
       " '고',\n",
       " '탄호이저',\n",
       " '에',\n",
       " '도',\n",
       " '착수',\n",
       " '하',\n",
       " '는',\n",
       " '등',\n",
       " '분주',\n",
       " '한',\n",
       " '시간',\n",
       " '을',\n",
       " '보냈',\n",
       " '는데',\n",
       " ',',\n",
       " '그런',\n",
       " '바쁜',\n",
       " '생활',\n",
       " '이',\n",
       " '이',\n",
       " '곡',\n",
       " '을',\n",
       " '잊',\n",
       " '게',\n",
       " '한',\n",
       " '것',\n",
       " '이',\n",
       " '아닌가',\n",
       " '하',\n",
       " '는',\n",
       " '의견',\n",
       " '도',\n",
       " '있',\n",
       " '다',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 갯수 : 83593\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for i in range(len(corpus_data)):\n",
    "    vocab.update(corpus_data[i])\n",
    "    \n",
    "print('단어 갯수 : ' + str(len(vocab)))\n",
    "\n",
    "word_to_id = dict()\n",
    "for word in vocab:\n",
    "    word_to_id[word]=len(word_to_id)    \n",
    "    \n",
    "id_to_word = []\n",
    "for word in word_to_id.keys():\n",
    "    id_to_word.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['바그너',\n",
       " '는',\n",
       " '괴테',\n",
       " '의',\n",
       " '파우스트',\n",
       " '를',\n",
       " '읽',\n",
       " '고',\n",
       " '무엇',\n",
       " '을',\n",
       " '쓰',\n",
       " '고자',\n",
       " '했',\n",
       " '는가',\n",
       " '?',\n",
       " '교향곡']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_ngram(n, sent):\n",
    "    ngrams = []\n",
    "    \n",
    "    for i in range(n, len(sent)-n):\n",
    "        ngram = []\n",
    "        for j in range(-n,n+1):\n",
    "            ngram.append(sent[i+j])\n",
    "        ngrams.append(ngram)\n",
    "            \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['바그너', '는', '괴테', '의', '파우스트', '를', '읽'],\n",
       " ['는', '괴테', '의', '파우스트', '를', '읽', '고'],\n",
       " ['괴테', '의', '파우스트', '를', '읽', '고', '무엇'],\n",
       " ['의', '파우스트', '를', '읽', '고', '무엇', '을'],\n",
       " ['파우스트', '를', '읽', '고', '무엇', '을', '쓰'],\n",
       " ['를', '읽', '고', '무엇', '을', '쓰', '고자'],\n",
       " ['읽', '고', '무엇', '을', '쓰', '고자', '했'],\n",
       " ['고', '무엇', '을', '쓰', '고자', '했', '는가'],\n",
       " ['무엇', '을', '쓰', '고자', '했', '는가', '?'],\n",
       " ['을', '쓰', '고자', '했', '는가', '?', '교향곡']]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_to_ngram(3,corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(corpus_data)):\n",
    "    train_data += sent_to_ngram(N, corpus_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_vec(sent):\n",
    "    vec = []\n",
    "    for word in sent:\n",
    "        vec.append(word_to_id[word])\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['바그너', '는', '괴테', '의', '파우스트', '를', '읽']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_to_ngram(3,corpus_data[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([26494, 31901, 26200, 81583, 14801, 45264, 59443],\n",
       " [31901, 26200, 81583, 14801, 45264, 59443, 70316])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_to_vec(train_data[0]),sent_to_vec(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_target = []\n",
    "for data in train_data:\n",
    "    train_input.append(sent_to_vec(data[:N])+sent_to_vec(data[N+1:]))\n",
    "    train_target.append(word_to_id[data[N]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(torch.tensor(train_input), torch.tensor(train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vec_dim):\n",
    "        super(CBOW,self).__init__()\n",
    "        self.emb = nn.Embedding(len(vocab), vec_dim)\n",
    "        self.lin = nn.Linear(vec_dim, len(vocab), bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.mean(self.emb(x), dim=1)\n",
    "        x = self.lin(x).view(-1,len(vocab))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(VEC_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (emb): Embedding(83593, 100)\n",
       "  (lin): Linear(in_features=100, out_features=83593, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = 1000\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Iteration : 0, Loss : 0.01, Elapsed time : 0h 0m 0s\n",
      "Epoch : 0, Iteration : 1000, Loss : 6.90, Elapsed time : 0h 0m 18s\n",
      "Epoch : 0, Iteration : 2000, Loss : 6.76, Elapsed time : 0h 0m 37s\n",
      "Epoch : 0, Iteration : 3000, Loss : 6.66, Elapsed time : 0h 0m 56s\n",
      "Epoch : 0, Iteration : 4000, Loss : 6.46, Elapsed time : 0h 1m 15s\n",
      "Epoch : 0, Iteration : 5000, Loss : 6.39, Elapsed time : 0h 1m 34s\n",
      "Epoch : 0, Iteration : 6000, Loss : 6.29, Elapsed time : 0h 1m 53s\n",
      "Epoch : 0, Iteration : 7000, Loss : 6.30, Elapsed time : 0h 2m 12s\n",
      "Epoch : 0, Iteration : 8000, Loss : 6.31, Elapsed time : 0h 2m 31s\n",
      "Epoch : 0, Iteration : 9000, Loss : 6.32, Elapsed time : 0h 2m 50s\n",
      "Epoch : 0, Iteration : 10000, Loss : 6.05, Elapsed time : 0h 3m 8s\n",
      "Epoch : 0, Iteration : 11000, Loss : 5.86, Elapsed time : 0h 3m 27s\n",
      "Epoch : 0, Iteration : 12000, Loss : 6.04, Elapsed time : 0h 3m 46s\n",
      "Epoch : 0, Iteration : 13000, Loss : 6.02, Elapsed time : 0h 4m 4s\n",
      "Epoch : 0, Iteration : 14000, Loss : 5.98, Elapsed time : 0h 4m 23s\n",
      "Epoch : 0, Iteration : 15000, Loss : 5.93, Elapsed time : 0h 4m 41s\n",
      "Epoch : 0, Iteration : 16000, Loss : 5.97, Elapsed time : 0h 5m 0s\n",
      "Epoch : 0, Iteration : 17000, Loss : 5.90, Elapsed time : 0h 5m 19s\n",
      "Epoch : 0, Iteration : 18000, Loss : 5.87, Elapsed time : 0h 5m 37s\n",
      "Epoch : 0, Iteration : 19000, Loss : 5.82, Elapsed time : 0h 5m 56s\n",
      "Epoch : 0, Iteration : 20000, Loss : 5.85, Elapsed time : 0h 6m 15s\n",
      "Epoch : 0, Iteration : 21000, Loss : 5.74, Elapsed time : 0h 6m 34s\n",
      "Epoch : 0, Iteration : 22000, Loss : 5.96, Elapsed time : 0h 6m 52s\n",
      "Epoch : 0, Iteration : 23000, Loss : 5.90, Elapsed time : 0h 7m 11s\n",
      "Epoch : 0, Iteration : 24000, Loss : 5.82, Elapsed time : 0h 7m 30s\n",
      "Epoch : 0, Iteration : 25000, Loss : 5.81, Elapsed time : 0h 7m 49s\n",
      "Epoch : 0, Iteration : 26000, Loss : 5.74, Elapsed time : 0h 8m 7s\n",
      "Epoch : 0, Iteration : 27000, Loss : 5.71, Elapsed time : 0h 8m 26s\n",
      "Epoch : 0, Iteration : 28000, Loss : 5.78, Elapsed time : 0h 8m 45s\n"
     ]
    }
   ],
   "source": [
    "# GPU time\n",
    "start = time.time()\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for epo in range(epoch):\n",
    "    loss_sum = 0\n",
    "    for i, (x, y) in enumerate(input_loader):\n",
    "\n",
    "        x,y = x.to(dev), y.to(dev)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(x)\n",
    "        \n",
    "        loss = loss_f(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        \n",
    "        if i % check == 0:        \n",
    "            elap = int(time.time() - start)\n",
    "            loss_list.append(loss_sum/check)\n",
    "            print('Epoch : {}, Iteration : {}, Loss : {:.2f}, Elapsed time : {:.0f}h {:.0f}m {}s'.format(\\\n",
    "                epo, i, loss_sum / check, elap // 3600, (elap % 3600) // 60, str(int((elap % 3600) % 60))))\n",
    "            loss_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f0e4b3a0c8>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'CBOW_N3_1epoch.pt'#.format(epoch)\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (emb): Embedding(114937, 100)\n",
       "  (lin): Linear(in_features=100, out_features=114937, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'CBOW_5epoch.pt'\n",
    "model = CBOW(VEC_DIM)\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_words(model, word, k=10):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    \n",
    "    word_id = torch.tensor([word_to_id[word]])\n",
    "    word_vec = model.emb(word_id)\n",
    "    word_mat = next(iter(model.emb.parameters())).detach()\n",
    "    \n",
    "    cos_mat = cos(word_vec, word_mat)\n",
    "    sim, indices = torch.topk(cos_mat,k+1)\n",
    "    \n",
    "    \n",
    "    word_list = []\n",
    "    for i in indices:\n",
    "        if i != word_id:\n",
    "            word_list.append(id_to_word[i])\n",
    "    return word_list, sim[1:].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['곳', '시장', '민족', '구간', '빌리치', '영역', '지방', '나라', '간담', '붕당'],\n",
       " tensor([0.6377, 0.5033, 0.4792, 0.4789, 0.4776, 0.4514, 0.4473, 0.4390, 0.4388,\n",
       "         0.4383]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(model.to('cpu'), '지역')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['아버지', '아내', '그녀', '크기', '진정서', '인제', '피해자', '엄마', '정부', '세조'],\n",
       " tensor([0.5977, 0.5660, 0.5630, 0.5254, 0.5107, 0.4938, 0.4917, 0.4824, 0.4766,\n",
       "         0.4732]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(model.to('cpu'), '어머니')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['일본', '한국', '미국', '우라야스', '자국', '중국', '에스토니아', '왜관', 'Στίλβων', '대부분'],\n",
       " tensor([0.5484, 0.4867, 0.4831, 0.4346, 0.4197, 0.4153, 0.4115, 0.4053, 0.4029,\n",
       "         0.4027]))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(model.to('cpu'), '대한민국')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['정보', '캐릭터', '성능', '예물', '상식', '가치', '인터페이스', '변화', '으신다', '병리'],\n",
       " tensor([0.4606, 0.4514, 0.4488, 0.4450, 0.4408, 0.4169, 0.4166, 0.4081, 0.4036,\n",
       "         0.4032]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(model.to('cpu'), '컴퓨터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words(model.to('cpu'), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(model, word1, word2, word3,k=10):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    \n",
    "    word_id1 = torch.tensor([word_to_id[word1]])\n",
    "    word_id2 = torch.tensor([word_to_id[word2]])\n",
    "    word_id3 = torch.tensor([word_to_id[word3]])\n",
    "    word_vec1 = model.emb(word_id1)\n",
    "    word_vec2 = model.emb(word_id2)\n",
    "    word_vec3 = model.emb(word_id3)\n",
    "    word_mat = next(iter(model.emb.parameters())).detach()\n",
    "    \n",
    "    cos_mat = cos(word_vec1-word_vec2+word_vec3, word_mat)\n",
    "    sim, indices = torch.topk(cos_mat,k)\n",
    "    \n",
    "    \n",
    "    word_list = []\n",
    "    for i in indices:\n",
    "        word_list.append(id_to_word[i])\n",
    "    return word_list, sim[1:].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['파리', '한국', '참전', '산량', '입대', '사염', '걸쳐서', '프랑스와', '달했으며', '발매되'],\n",
       " tensor([0.5320, 0.5006, 0.3921, 0.3908, 0.3891, 0.3889, 0.3769, 0.3733, 0.3731]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(model,'한국','서울','파리')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['왕', '동반성', '합당', '신탁', '핀란드어', '왕위', '여자', '와이드', '크시슈토프', '콜먼'],\n",
       " tensor([0.4096, 0.4065, 0.4057, 0.3908, 0.3795, 0.3704, 0.3678, 0.3669, 0.3643]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(model,'왕','남자','여자')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N=5 일때보다 N=3 으로 하니까 뭔가 잘되는 느낌...\n",
    "이제 skip-gram으로 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이번엔 Skip-gram 모델...\n",
    "\n",
    "먼저 훈련데이터 형식을 [중심단어, 문맥단어] 으로 바꾸자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_input = []\n",
    "train_target = []\n",
    "for data in train_data:\n",
    "    target = sent_to_vec(data[:N])+sent_to_vec(data[N+1:])\n",
    "    for i in range(len(target)):\n",
    "        train_input.append(word_to_id[data[N]])\n",
    "        train_target.append(target[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1', '8', '3', '9', '년', '바그너', '는'], ['8', '3', '9', '년', '바그너', '는', '괴테'])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26494, 31901, 26200, 81583, 14801, 45264, 59443]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_to_vec(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81583, 26494)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0], train_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21793818, 21793818)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input), len(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(torch.tensor(train_input), torch.tensor(train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(len(vocab), VEC_DIM)\n",
    "lin = nn.Linear(VEC_DIM, len(vocab), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "input_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    def __init__(self, vec_dim):\n",
    "        super(Skipgram,self).__init__()\n",
    "        self.emb = nn.Embedding(len(vocab), vec_dim)\n",
    "        self.lin = nn.Linear(vec_dim, len(vocab), bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.lin(x)#.view(-1,len(vocab))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sg = Skipgram(VEC_DIM).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_sg.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = 5000\n",
    "epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (emb): Embedding(83593, 100)\n",
       "  (lin): Linear(in_features=100, out_features=83593, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Iteration : 0, Loss : 0.00, Elapsed time : 0h 0m 1s\n",
      "Epoch : 0, Iteration : 5000, Loss : 7.39, Elapsed time : 0h 1m 33s\n",
      "Epoch : 0, Iteration : 10000, Loss : 7.40, Elapsed time : 0h 3m 6s\n",
      "Epoch : 0, Iteration : 15000, Loss : 7.40, Elapsed time : 0h 4m 39s\n",
      "Epoch : 0, Iteration : 20000, Loss : 7.39, Elapsed time : 0h 6m 11s\n",
      "Epoch : 0, Iteration : 25000, Loss : 7.40, Elapsed time : 0h 7m 41s\n",
      "Epoch : 0, Iteration : 30000, Loss : 7.39, Elapsed time : 0h 9m 13s\n",
      "Epoch : 0, Iteration : 35000, Loss : 7.38, Elapsed time : 0h 10m 45s\n",
      "Epoch : 0, Iteration : 40000, Loss : 7.38, Elapsed time : 0h 12m 18s\n",
      "Epoch : 0, Iteration : 45000, Loss : 7.36, Elapsed time : 0h 13m 51s\n",
      "Epoch : 0, Iteration : 50000, Loss : 7.36, Elapsed time : 0h 15m 24s\n",
      "Epoch : 0, Iteration : 55000, Loss : 7.36, Elapsed time : 0h 16m 57s\n",
      "Epoch : 0, Iteration : 60000, Loss : 7.36, Elapsed time : 0h 18m 30s\n",
      "Epoch : 0, Iteration : 65000, Loss : 7.35, Elapsed time : 0h 20m 3s\n",
      "Epoch : 0, Iteration : 70000, Loss : 7.35, Elapsed time : 0h 21m 36s\n",
      "Epoch : 0, Iteration : 75000, Loss : 7.35, Elapsed time : 0h 23m 9s\n",
      "Epoch : 0, Iteration : 80000, Loss : 7.35, Elapsed time : 0h 24m 42s\n",
      "Epoch : 0, Iteration : 85000, Loss : 7.35, Elapsed time : 0h 26m 15s\n",
      "Epoch : 0, Iteration : 90000, Loss : 7.36, Elapsed time : 0h 27m 48s\n",
      "Epoch : 0, Iteration : 95000, Loss : 7.36, Elapsed time : 0h 29m 21s\n",
      "Epoch : 0, Iteration : 100000, Loss : 7.36, Elapsed time : 0h 30m 55s\n",
      "Epoch : 0, Iteration : 105000, Loss : 7.36, Elapsed time : 0h 32m 28s\n",
      "Epoch : 0, Iteration : 110000, Loss : 7.37, Elapsed time : 0h 34m 1s\n",
      "Epoch : 0, Iteration : 115000, Loss : 7.38, Elapsed time : 0h 35m 34s\n",
      "Epoch : 0, Iteration : 120000, Loss : 7.38, Elapsed time : 0h 37m 4s\n",
      "Epoch : 0, Iteration : 125000, Loss : 7.38, Elapsed time : 0h 38m 34s\n",
      "Epoch : 0, Iteration : 130000, Loss : 7.38, Elapsed time : 0h 40m 6s\n",
      "Epoch : 0, Iteration : 135000, Loss : 7.39, Elapsed time : 0h 41m 39s\n",
      "Epoch : 0, Iteration : 140000, Loss : 7.39, Elapsed time : 0h 43m 12s\n",
      "Epoch : 0, Iteration : 145000, Loss : 7.40, Elapsed time : 0h 44m 44s\n",
      "Epoch : 0, Iteration : 150000, Loss : 7.39, Elapsed time : 0h 46m 17s\n",
      "Epoch : 0, Iteration : 155000, Loss : 7.40, Elapsed time : 0h 47m 49s\n",
      "Epoch : 0, Iteration : 160000, Loss : 7.40, Elapsed time : 0h 49m 22s\n",
      "Epoch : 0, Iteration : 165000, Loss : 7.40, Elapsed time : 0h 50m 55s\n",
      "Epoch : 0, Iteration : 170000, Loss : 7.40, Elapsed time : 0h 52m 27s\n",
      "Epoch : 1, Iteration : 0, Loss : 0.00, Elapsed time : 0h 52m 34s\n",
      "Epoch : 1, Iteration : 5000, Loss : 7.35, Elapsed time : 0h 54m 7s\n",
      "Epoch : 1, Iteration : 10000, Loss : 7.37, Elapsed time : 0h 55m 39s\n",
      "Epoch : 1, Iteration : 15000, Loss : 7.37, Elapsed time : 0h 57m 12s\n",
      "Epoch : 1, Iteration : 20000, Loss : 7.37, Elapsed time : 0h 58m 45s\n",
      "Epoch : 1, Iteration : 25000, Loss : 7.36, Elapsed time : 1h 0m 18s\n",
      "Epoch : 1, Iteration : 30000, Loss : 7.36, Elapsed time : 1h 1m 51s\n",
      "Epoch : 1, Iteration : 35000, Loss : 7.37, Elapsed time : 1h 3m 24s\n",
      "Epoch : 1, Iteration : 40000, Loss : 7.35, Elapsed time : 1h 4m 58s\n",
      "Epoch : 1, Iteration : 45000, Loss : 7.35, Elapsed time : 1h 6m 31s\n",
      "Epoch : 1, Iteration : 50000, Loss : 7.34, Elapsed time : 1h 8m 4s\n",
      "Epoch : 1, Iteration : 55000, Loss : 7.34, Elapsed time : 1h 9m 38s\n",
      "Epoch : 1, Iteration : 60000, Loss : 7.33, Elapsed time : 1h 11m 11s\n",
      "Epoch : 1, Iteration : 65000, Loss : 7.32, Elapsed time : 1h 12m 44s\n",
      "Epoch : 1, Iteration : 70000, Loss : 7.33, Elapsed time : 1h 14m 17s\n",
      "Epoch : 1, Iteration : 75000, Loss : 7.34, Elapsed time : 1h 15m 50s\n",
      "Epoch : 1, Iteration : 80000, Loss : 7.34, Elapsed time : 1h 17m 24s\n",
      "Epoch : 1, Iteration : 85000, Loss : 7.34, Elapsed time : 1h 18m 57s\n",
      "Epoch : 1, Iteration : 90000, Loss : 7.35, Elapsed time : 1h 20m 30s\n",
      "Epoch : 1, Iteration : 95000, Loss : 7.34, Elapsed time : 1h 22m 3s\n",
      "Epoch : 1, Iteration : 100000, Loss : 7.35, Elapsed time : 1h 23m 36s\n",
      "Epoch : 1, Iteration : 105000, Loss : 7.36, Elapsed time : 1h 25m 9s\n",
      "Epoch : 1, Iteration : 110000, Loss : 7.36, Elapsed time : 1h 26m 42s\n",
      "Epoch : 1, Iteration : 115000, Loss : 7.36, Elapsed time : 1h 28m 15s\n",
      "Epoch : 1, Iteration : 120000, Loss : 7.37, Elapsed time : 1h 29m 48s\n",
      "Epoch : 1, Iteration : 125000, Loss : 7.39, Elapsed time : 1h 31m 21s\n",
      "Epoch : 1, Iteration : 130000, Loss : 7.38, Elapsed time : 1h 32m 54s\n",
      "Epoch : 1, Iteration : 135000, Loss : 7.39, Elapsed time : 1h 34m 27s\n",
      "Epoch : 1, Iteration : 140000, Loss : 7.39, Elapsed time : 1h 36m 0s\n",
      "Epoch : 1, Iteration : 145000, Loss : 7.39, Elapsed time : 1h 37m 33s\n",
      "Epoch : 1, Iteration : 150000, Loss : 7.41, Elapsed time : 1h 39m 7s\n",
      "Epoch : 1, Iteration : 155000, Loss : 7.41, Elapsed time : 1h 40m 40s\n",
      "Epoch : 1, Iteration : 160000, Loss : 7.41, Elapsed time : 1h 42m 13s\n",
      "Epoch : 1, Iteration : 165000, Loss : 7.41, Elapsed time : 1h 43m 46s\n",
      "Epoch : 1, Iteration : 170000, Loss : 7.42, Elapsed time : 1h 45m 20s\n"
     ]
    }
   ],
   "source": [
    "# GPU time\n",
    "start = time.time()\n",
    "\n",
    "#loss_list = []\n",
    "\n",
    "for epo in range(epoch):\n",
    "    loss_sum = 0\n",
    "    for i, (x, y) in enumerate(input_loader):\n",
    "\n",
    "        x,y = x.to(dev), y.to(dev)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model_sg(x)\n",
    "        \n",
    "        loss = loss_f(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        \n",
    "        if i % check == 0:        \n",
    "            elap = int(time.time() - start)\n",
    "            loss_list.append(loss_sum/check)\n",
    "            print('Epoch : {}, Iteration : {}, Loss : {:.2f}, Elapsed time : {:.0f}h {:.0f}m {}s'.format(\\\n",
    "                epo, i, loss_sum / check, elap // 3600, (elap % 3600) // 60, str(int((elap % 3600) % 60))))\n",
    "            loss_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f0e4aee808>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'SG_N3_3epoch.pt'#.format(epoch)\n",
    "torch.save(model_sg.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['과', '유아사', '득실거리', '보모', '지코', '김정화', '검찰청', '속하', '장소', '지금'],\n",
       " tensor([0.5190, 0.4759, 0.4567, 0.4330, 0.4231, 0.4205, 0.4199, 0.4187, 0.4139,\n",
       "         0.4085]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(model_sg.to('cpu'), '지역')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['선조', '그', '백록', '장기하', '하치조', '오스', '루시', '에른스트', '아이', '데뷔작'],\n",
       " tensor([0.4927, 0.4756, 0.4455, 0.4180, 0.4145, 0.4031, 0.3993, 0.3988, 0.3967,\n",
       "         0.3941]))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(model_sg.to('cpu'), '어머니')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['및', '년', '아시아', '병력', '5', '선거', '본부', '인천', '7', '론'],\n",
       " tensor([0.4887, 0.4550, 0.4481, 0.4243, 0.4039, 0.4027, 0.3944, 0.3941, 0.3936,\n",
       "         0.3915]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(model_sg.to('cpu'), '대한민국')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['에볼라', '고래', '부분', '윔', '느낀다는', '스몰', '인화물', '편곡', '초신성', '아이템'],\n",
       " tensor([0.4224, 0.4050, 0.3938, 0.3918, 0.3844, 0.3837, 0.3787, 0.3598, 0.3581,\n",
       "         0.3569]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words(model_sg.to('cpu'), '컴퓨터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['파리', '원정', '한국', '바이크', '벌목', '사이펀', '겨우', '박신양', '동부', '허물'],\n",
       " tensor([0.4750, 0.4459, 0.4239, 0.4016, 0.3893, 0.3867, 0.3844, 0.3778, 0.3735]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(model_sg,'한국','서울','파리')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
